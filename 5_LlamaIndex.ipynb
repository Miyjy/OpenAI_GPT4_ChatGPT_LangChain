{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1XMWWK6JeWh-QBTdBgCwklYtXeRJPZ-hz","timestamp":1695608681102},{"file_id":"1-r1wyzpjtv_rYjvRvqVorhVg4sPJi0wU","timestamp":1693541289732}],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyMUmqarKkF9e13Gbxiqmt+T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# LLMA"],"metadata":{"id":"pXe4Za9MZSha"}},{"cell_type":"markdown","source":["LLaMA（Large Language Model Meta AI）は、Meta AI が2023年2月に発表した大規模言語モデル\n","\n","4つのモデルサイズ: 7B（70億）、13B（130億）、30B（300億）、65B（650億）\n","\n","70億パラメータから650億パラメータまで、さまざまなサイズのモデルが学習されたモデル\n","\n","130億パラメータモデルがほとんどのNLPベンチマークにおいてGPT-3（1750億パラメータ）の性能を上回る\n","\n","Meta は LLaMA のモデルのウェイトを非商用ライセンスで研究コミュニティに公開した\n","\n","1.4兆個のトークンで学習したモデル\n","\n","スタンフォード大学の基盤モデル研究センター（Center for Research on Foundation Models, CRFM）は、LLaMA の 70億パラメータ・モデルをファイン・チューニングした、Alpaca をリリース\n","\n","Alpaca は OpenAI GPT-3.5シリーズの text-davinci-003モデルに相当する性能がある\n","\n","<figure>\n","<a href=\"https://github.com/tatsu-lab/stanford_alpaca\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.1.png' alt='CRFMの70億パラメータLLaMAモデルーAlpaca' width='640' border='1'></a>\n","</figure>\n","\n","<!-- <img src=\"https://github.com/tatsu-lab/stanford_alpaca/raw/main/assets/logo.png\" alt=\"参考図：スタンフォード大学より\"> -->\n","\n","図5.1. 出所:スタンフォード大学公式Webサイト |CRFMの70億パラメータLLaMAモデルーAlpaca\n","\n","\n","\n","\n"],"metadata":{"id":"XsYZAM9zZRr3"}},{"cell_type":"markdown","source":["## Alpaca LLaMA\n","\n","チャットアプリケーションに特化したLLM\n","\n","Alpacaは、より自然で流暢な会話を生成するために、コミュニケーションスキルや対話戦略を学習されている\n","\n","Alpacaはより人間らしい回答を提供する\n","\n","金融機関の金融商品についての言語処理を例とする\n","\n","ある企業の株コードを入力し、決まったコード入力しただけで、市場の株価から始め市場分析まで可能である\n","\n"],"metadata":{"id":"ykKBLCBSwyl7"}},{"cell_type":"markdown","source":["### LLMAをAPI経由での利用方法"],"metadata":{"id":"MTFeWGPvhN-E"}},{"cell_type":"markdown","source":["Alpacaアカウントを登録\n","\n","https://app.alpaca.markets/signup\n","\n","メール、PW、ユーザー名入力で登録が可能"],"metadata":{"id":"cXw0T7r-h7Ms"}},{"cell_type":"markdown","source":["インストール"],"metadata":{"id":"yNML4iKZxk6e"}},{"cell_type":"code","source":["!pip install alpaca-trade-api\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dseet3Dgh653","executionInfo":{"status":"ok","timestamp":1692932057474,"user_tz":-540,"elapsed":10424,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"aa99eefa-5a3b-4b9a-e3b5-9548f1c74282"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting alpaca-trade-api\n","  Downloading alpaca_trade_api-3.0.2-py3-none-any.whl (34 kB)\n","Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api) (1.5.3)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api) (1.23.5)\n","Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api) (2.31.0)\n","Collecting urllib3<2,>1.24 (from alpaca-trade-api)\n","  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api) (1.6.1)\n","Collecting websockets<11,>=9.0 (from alpaca-trade-api)\n","  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting msgpack==1.0.3 (from alpaca-trade-api)\n","  Downloading msgpack-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.7/323.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohttp==3.8.2 (from alpaca-trade-api)\n","  Downloading aiohttp-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyYAML==6.0 (from alpaca-trade-api)\n","  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting deprecation==2.1.0 (from alpaca-trade-api)\n","  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api) (23.1.0)\n","Collecting charset-normalizer<3.0,>=2.0 (from aiohttp==3.8.2->alpaca-trade-api)\n","  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n","Collecting multidict<6.0,>=4.5 (from aiohttp==3.8.2->alpaca-trade-api)\n","  Downloading multidict-5.2.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (175 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api) (1.3.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation==2.1.0->alpaca-trade-api) (23.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18.1->alpaca-trade-api) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18.1->alpaca-trade-api) (2023.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>2->alpaca-trade-api) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>2->alpaca-trade-api) (2023.7.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.18.1->alpaca-trade-api) (1.16.0)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'aiohttp' candidate (version 3.8.2 at https://files.pythonhosted.org/packages/8f/52/ea1e5eac3e748a94fdaafba5ab68adfb833f0cbdb68cc8149fbba5574176/aiohttp-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/aiohttp/) (requires-python:>=3.6))\n","Reason for being yanked: This version includes overly restrictive multidict upper boundary disallowing multidict v6+. The previous patch version didn't have that and this is now causing dependency resolution problems for the users who have an \"incompatible\" version pinned. This is not really necessary anymore and will be addressed in the next release v3.8.3\n","\n","https://github.com/aio-libs/aiohttp/pull/6950\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: msgpack, websockets, urllib3, PyYAML, multidict, deprecation, charset-normalizer, aiohttp, alpaca-trade-api\n","  Attempting uninstall: msgpack\n","    Found existing installation: msgpack 1.0.5\n","    Uninstalling msgpack-1.0.5:\n","      Successfully uninstalled msgpack-1.0.5\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.0.4\n","    Uninstalling urllib3-2.0.4:\n","      Successfully uninstalled urllib3-2.0.4\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 6.0.1\n","    Uninstalling PyYAML-6.0.1:\n","      Successfully uninstalled PyYAML-6.0.1\n","  Attempting uninstall: multidict\n","    Found existing installation: multidict 6.0.4\n","    Uninstalling multidict-6.0.4:\n","      Successfully uninstalled multidict-6.0.4\n","  Attempting uninstall: charset-normalizer\n","    Found existing installation: charset-normalizer 3.2.0\n","    Uninstalling charset-normalizer-3.2.0:\n","      Successfully uninstalled charset-normalizer-3.2.0\n","  Attempting uninstall: aiohttp\n","    Found existing installation: aiohttp 3.8.5\n","    Uninstalling aiohttp-3.8.5:\n","      Successfully uninstalled aiohttp-3.8.5\n","Successfully installed PyYAML-6.0 aiohttp-3.8.2 alpaca-trade-api-3.0.2 charset-normalizer-2.1.1 deprecation-2.1.0 msgpack-1.0.3 multidict-5.2.0 urllib3-1.26.16 websockets-10.4\n"]}]},{"cell_type":"markdown","source":["APIキーを入力し、Alpacaモデルにアクセス"],"metadata":{"id":"XTANYlj8xN-9"}},{"cell_type":"code","source":["import alpaca_trade_api as tradeapi\n","\n","# Set your API keys here\n","API_KEY = 'your_api_key'\n","SECRET_KEY = 'your_secret_key'\n","\n","# Create an instance of the Alpaca API\n","api = tradeapi.REST(API_KEY, SECRET_KEY, base_url='https://paper-api.alpaca.markets')  # Use paper trading API endpoint\n"],"metadata":{"id":"ZQmSBza4iKDj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["アップル株式会社(APPL)の株について調べる"],"metadata":{"id":"cj7fFD3Qh8K4"}},{"cell_type":"code","source":["# Define the stock symbol and the number of shares to buy\n","symbol = 'AAPL'\n","qty = 10\n","\n","# Place a market order to buy\n","api.submit_order(\n","    symbol=symbol,\n","    qty=qty,\n","    side='buy',\n","    type='market',\n","    time_in_force='gtc'  # Good 'til cancelled\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSJvK6x3h6nq","executionInfo":{"status":"ok","timestamp":1692932068871,"user_tz":-540,"elapsed":1617,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"218b200d-f644-422b-dbe0-7c401059270f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Order({   'asset_class': 'us_equity',\n","    'asset_id': 'b0b6dd9d-8b9b-48a9-ba46-b9d54906e415',\n","    'canceled_at': None,\n","    'client_order_id': '0e61a67c-67ac-47c0-bfe2-50b1f415c475',\n","    'created_at': '2023-08-25T02:54:27.299601184Z',\n","    'expired_at': None,\n","    'extended_hours': False,\n","    'failed_at': None,\n","    'filled_at': None,\n","    'filled_avg_price': None,\n","    'filled_qty': '0',\n","    'hwm': None,\n","    'id': 'e75c9c9f-c3da-478a-8e15-1c137eaf3c68',\n","    'legs': None,\n","    'limit_price': None,\n","    'notional': None,\n","    'order_class': '',\n","    'order_type': 'market',\n","    'qty': '10',\n","    'replaced_at': None,\n","    'replaced_by': None,\n","    'replaces': None,\n","    'side': 'buy',\n","    'source': None,\n","    'status': 'accepted',\n","    'stop_price': None,\n","    'submitted_at': '2023-08-25T02:54:27.299007364Z',\n","    'subtag': None,\n","    'symbol': 'AAPL',\n","    'time_in_force': 'gtc',\n","    'trail_percent': None,\n","    'trail_price': None,\n","    'type': 'market',\n","    'updated_at': '2023-08-25T02:54:27.299601184Z'})"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["アカウント状況、買付余力、資産額などを調べる"],"metadata":{"id":"ENwWlRJjx93M"}},{"cell_type":"code","source":["# Get account information\n","account = api.get_account()\n","print(f\"Account status: ${account.status}\")\n","print(f\"Buying power: ${account.buying_power}\")\n","print(f\"Equity: ${account.equity}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"neNo_YnWh6kl","executionInfo":{"status":"ok","timestamp":1692932077143,"user_tz":-540,"elapsed":1352,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"5309914a-d4ab-4255-c1d8-2befc0b04bef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Account status: $ACTIVE\n","Buying power: $198236.5\n","Equity: $100000\n"]}]},{"cell_type":"markdown","source":["## Dalai LLaMA\n","\n","入力したプロンプトに対し、Ubuntu環境でのテキスト質問応答の実行を例とする"],"metadata":{"id":"1wV6hAAawkQg"}},{"cell_type":"markdown","source":["### Ubuntu環境でLLMAを利用する方法\n","\n","参考サイト\n","\n","https://qiita.com/mine820/items/4c10165cc92211aeed87\n","\n","Windowsネイティブな環境では動かないので、WSL環境を用意する必要がある\n","\n","（注:現在は、公式サイトにVisual Studio Communityを使った環境構築方法もある）\n","\n","以下の実践用コーディングは ubuntu 環境向けである\n","\n","名前は「ダライ・ラマ」から来ている？"],"metadata":{"id":"YXIsJdutbyQo"}},{"cell_type":"markdown","source":["#### 利用前環境構築について"],"metadata":{"id":"TpAcBhZodTWq"}},{"cell_type":"markdown","source":["WSL環境を更新"],"metadata":{"id":"Dusi3QBkbrjc"}},{"cell_type":"code","source":["sudo apt update\n","sudo apt upgrade -y\n","sudo apt dist-upgrade -y\n","sudo apt autoremove -y\n"],"metadata":{"id":"pYXOqPejbnZq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Node.jsをインストール\n","\n","そのため、まずはnvmをインストールする"],"metadata":{"id":"lYTbsK0bbsBi"}},{"cell_type":"code","source":["sudo apt install curl\n","curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash\n","source ~/.bashrc\n"],"metadata":{"id":"4waLEvr4cz8A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nvm install node"],"metadata":{"id":"5x2tlzEnbrGw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["pythonをインストール"],"metadata":{"id":"-GsJFnqhbsgJ"}},{"cell_type":"code","source":["sudo apt install python3 -y"],"metadata":{"id":"_xkX4j9VbrCF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["venvのインストール"],"metadata":{"id":"4gxLLoz7bs8n"}},{"cell_type":"code","source":["sudo apt install python3.8-venv"],"metadata":{"id":"XBFHTsM8bq-J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["「Dalai」のNode.jsをインストール\n","\n","モデル番号を指定"],"metadata":{"id":"J6-UonISbtaT"}},{"cell_type":"code","source":["npx dalai llama"],"metadata":{"id":"lWfKcLxqbq6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["npx dalai llama 7B 13B 30B 65B"],"metadata":{"id":"WgnVLl0GdM-m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 実行について"],"metadata":{"id":"qXw_GA3rbt1A"}},{"cell_type":"code","source":["npx dalai serve\n"],"metadata":{"id":"ghAGHfOwbq3E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["（後ろにポート番号を付けることもできる）\n","\n","Webブラウザから「http://localhost:3000」にアクセス"],"metadata":{"id":"duKq3f9SbuSE"}},{"cell_type":"markdown","source":["dalai llama モデル画面が表示される\n","\n","<figure>\n","<a href=\"https://ai.meta.com/llama/\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.2.png' alt='Webブラウザへのアクセス後の表示画面' width='640' border='1'></a>\n","</figure>\n","\n","<!-- <img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F130771%2F9155d8d6-b3e9-5d78-5749-f8a985d1010a.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=ef7efd32a1b3836c984894384672c0d7\" alt=\"参考図：META AIより\"> -->\n","\n","図5.2. 出所:META AI公式Webサイト |Webブラウザへのアクセス後の表示画面\n"],"metadata":{"id":"CD8F9fx0er-l"}},{"cell_type":"markdown","source":["右上の「models」で、使用するモデルの変更が出来る\n","\n","7Bは英語のみ対応\n","\n","コマンドの例：\n","\n","        ./main --seed -1 --threads 4 --n_predict 1000 --model models/7B/ggml-model-q4_0.bin \\\n","          --top_k 40 --top_p 0.9 --temp 0.8 --repeat_last_n 64 --repeat_penalty 1.3 \\\n","          -p \"お金持ちになる方法を教えてください。\""],"metadata":{"id":"clqJgxBHbuli"}},{"cell_type":"markdown","source":["dalai llama モデル画面に\"お金持ちになる方法を教えてください。\"と入力したら結果が表示される\n","\n","<figure>\n","<a href=\"https://ai.meta.com/llama/\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.3.webp' alt='dalai llamaモデルの出力画面の例' width='640' border='1'></a>\n","</figure>\n","\n","<!-- <img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F130771%2F9103abf5-2c02-b795-85af-da7f2410db09.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=daeccb378f6fd56196bc02c79a184106\" alt=\"参考図：qiitaより\"> -->\n","\n","図5.3. 出所:qiita公式Webサイト |dalai llamaモデルの出力画面の例"],"metadata":{"id":"OYfGrat5fqo8"}},{"cell_type":"markdown","source":["#### バージョンを上げる方法\n","\n","（以下は、0.3.0に上げる場合の例）"],"metadata":{"id":"_m8HWw8nbvSS"}},{"cell_type":"code","source":["npx dalai@0.3.0 setup"],"metadata":{"id":"w_N1Y4WAbqs-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LLAMA 2\n","\n","LLMAより学習量が40%アップされ、しかもパラメーター数もより多いためコンテクストも2倍の長さまでプログラムできる"],"metadata":{"id":"1d0yj7REL-H0"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"https://ai.meta.com/llama/\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.4.png' alt='Meta AIのLlaMA2の学習パラメーター数' width='640' border='1'></a>\n","</figure>\n","\n","図5.4. 出所:META AI公式Webサイト |Meta AIのLlaMA2の学習パラメーター数"],"metadata":{"id":"wzpiDZS8WsqL"}},{"cell_type":"markdown","source":["## LLaMA-v2-Chat\n","\n","チャットアプリケーションに特化したLLM\n","\n","LLaMA-v2-Chatは、40%以上のデータで訓練され、コンテキスト長が2倍になり、人間の好みに基づいてチューニングされている\n","\n","あらゆるトピックに関する質問や、特定のプロンプトを使ってクリエイティブなコンテンツをリクエストすることができる\n","\n","一般的には、LLaMA-v2-Chatはより有用で安全な回答を提供できる\n","\n","\n","LLaMA-v2-Chatの実践Webサイト:\n","\n","https://www.llama2.ai/\n","\n","実際のチャート対話のビデオ再生リンク:\n","\n","https://replicate.com/static/blog/llama-api/llama-chat-demo.mp4"],"metadata":{"id":"HN37DQUM0Vq7"}},{"cell_type":"markdown","source":["### APIによるLlama 2の実行例\n","\n","LlaMA-v2-ChatはWebサイトで検索が可能で、実践コード作成は不要\n","\n","ただし、ReplicateのパッケージでLlama 2によってファインチューニングのコーディング実践例はリンクにて確認できる\n","\n","参考サイト\n","\n","https://replicate.com/blog/fine-tune-llama-2"],"metadata":{"id":"OIIAiccx8ExJ"}},{"cell_type":"markdown","source":["## Meta AIによって開発された最新の大規模言語モデル（LLM）Code Llama\n","\n","参考サイト\n","https://ai.meta.com/blog/code-llama-large-language-model-coding/\n","\n","モデルのダウンロード\n","\n","https://ai.meta.com/resources/models-and-libraries/llama-downloads/\n","\n","\n","利用ガイダンス\n","\n","https://github.com/facebookresearch/codellama"],"metadata":{"id":"-UiSozw3MBik"}},{"cell_type":"markdown","source":["Code Llamaはコード生成の分野で最先端の技術である\n","\n","コードの理解や生成を支援する言語モデルは非常に有益なモデルである\n","\n","「Code Llama」はLlama 2をベースに構築されている\n","\n","* 基本となる「Code Llama」\n","* Pythonプログラミングに特化した「Code Llama - Python」\n","* 自然言語の指示を理解するように微調整された「Code Llama - Instruct」\n","\n","* 機能\n","\n","「Code Llama」は、コードとコードに関連する自然言語のプロンプトからコードと自然言語を生成する\n","\n","自動補完、コード合成、関数やプログラムの作成などのタスクに役立つ\n","\n","* パラメーター\n","\n","65 billionパラメータを持つLLaMA(Large Language Model Meta AI)の基本モデルをベースにしている\n","\n","5000億トークンのコードの大規模なデータセットで訓練されている\n","\n","<figure>\n","<a href=\"https://blog.desdelinux.net/hu/h%C3%ADvja-a-c%C3%A9lt/\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.5.png' alt='Meta AIのLlaMA2のトレーニングトークン数' width='640' border='1'></a>\n","</figure>\n","\n","図5.5. 出所: META AI公式Webサイト |Meta AIのLlaMA2のトレーニングトークン数\n","\n","<figure>\n","<a href=\"https://ai.meta.com/blog/code-llama-large-language-model-coding/\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.6.png' alt='全てのLLaMAモデルにおける学習ロス対トークン数のグラフ' width='640' border='1'></a>\n","</figure>\n","\n","図5.6. 出所:META AI公式Webサイト |Meta AIのLlaMA2における各パラメーターに対する評価精度の比較表\n","\n","* 利用料金\n","\n","研究および商用利用のために無料で提供されている\n","\n","* サポートする言語\n","\n","現代で一般的に使用されるさまざまなプログラミング言語（Python, C++, Java, PHP, Typescript (Javascript), C#, and Bash）をサポートできるから汎用性のあるツールとなっている\n","\n"],"metadata":{"id":"dpb-lr3fLzxm"}},{"cell_type":"markdown","source":["利用例１:\n","\n","プログラム作成に関する質問に対し、コーディングとともに説明を出力する\n","\n","<figure>\n","<a href=\"https://gigazine.net/news/20230719-llama-2-chatbot/\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.7.png' alt='Metaの大規模言語モデル「Llama 2」を無料で誰でもブラウザからお試しできる「LLaMA2 Chatbot」' width='640' border='1'></a>\n","</figure>\n","\n","<!-- <img src=\"https://i.gzn.jp/img/2023/07/19/llama-2-chatbot/00_m.png\" alt=\"参考図： GIGAZINEより\"> -->\n","\n","図5.7. 出所: GIGAZINE公式Webサイト |Metaの大規模言語モデル「Llama 2」を無料で誰でもブラウザからお試しできる「LLaMA2 Chatbot」\n","\n","利用例２:\n","\n","細かいコーディングを出力できる\n","\n","<figure><a href=\"https://gigazine.net/news/20230719-llama-2-chatbot/\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.8.png' alt='細かいコーディングを出力する例' width='640' border='1'></a>\n","</figure>\n","\n","図5.8. 出所: META AI公式Webサイト |細かいコーディングを出力する例\n","\n","利用例3:\n","\n","CSVファイルやSeaborn可視化のプログラムを出力できる\n","\n","<figure><a href=\"https://gigazine.net/news/20230719-llama-2-chatbot/\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.9.png' alt='細かいコーディングを出力する例' width='640' border='1'></a>\n","</figure>\n","\n","図5.9. 出所: META AI公式Webサイト |CSVファイルやSeaborn可視化のプログラムを出力する例\n","\n"],"metadata":{"id":"PzqOnfhDK0eJ"}},{"cell_type":"markdown","source":["### Code Llama の実行例\n","\n","Code Llama はWebサイトで検索が可能で、実践コード作成は不要"],"metadata":{"id":"rj3kIkRMfign"}},{"cell_type":"markdown","source":["## LlamaIndex (GPT Index)"],"metadata":{"id":"OX-TU_DaEkIw"}},{"cell_type":"markdown","source":["| 名称  |説明 |\n","|--|--|\n","|LLM|GPTなどの大規模言語モデル|\n","|LangChain|LLMを使って自然言語処理のタスクを効率的に行うためのライブラリ|\n","||LLMに対して直接的に操作を行うことで、LLMの内部状態や出力を変化させることができる|\n","|LlamaIndex|外部データをLLMに渡すためのライブラリで、質問応答やチャットなどの機能を提供する|\n","||LLMに対して間接的に操作を行うことで、LLMの知識や応答を拡張することができる|\n","\n","LangChainとLlamaIndexは、LLMをカスタマイズするための2つのパラダイムを実現している\n","\n","* LangChain\n","\n","LLMをwebサービスや自作のAPI\n","\n","プログラムの実行環境\n","\n","ターミナルなどに接続するライブラリ\n","\n","提供するコンポーネント:\n","\n","|コンポーネント|\t説明|\n","|---|---|\n","|Models|\tOpenAIをはじめとした様々な言語モデル・チャットモデル・エンべディングモデルを切り替えたり、組み合わせたりすることができる|\n","|Prompt|\tプロンプトの管理・最適化・シリアル化などをすることができる|\n","Indexes|\tPDFやCSVなどの外部データを用いて回答を生成することができる|\n","|Chains|\t複数のプロンプト入力を実行することができる|\n","|Agents|\t言語モデルに渡されたツールを用いて、モデル自体が次にどのようなアクションを取るかを決定し、実行し、観測し、完了するまで繰り返すことができる|\n","Memory|\tChainsやAgentsの内部における状態保持をすることができる|\n"],"metadata":{"id":"QbRpcWf5H03T"}},{"cell_type":"markdown","source":["* LlamaIndex(GPT Indexとも呼ばれる）\n","\n","Webサイト:\n","\n","jerryjliu/lla,a_index\n","\n","https://github.com/jerryjliu/llama_index\n","\n","LlamaIndex 関連書類\n","\n","https://gpt-index.readthedocs.io/en/stable\n","\n","LlamaIndex:\n","\n","カスタムデータソースを大規模な言語モデルに接続するための有名なフレームワーク\n","\n","LLMで学習されていないデータを参照して、質問応答を作成するためのライブラリ「LlamaIndex」\n","\n","内部的には「LangChain」ライブラリを利用\n","\n","学習されていない情報を関連のLLMで参照する仕組みが特徴\n","\n","機能:\n","\n","独自のデータを使ったQAチャットができる\n","\n","LLMを簡単に作成できるライブラリ\n","\n","LLMをFine-tuningする\n","\n","入力プロンプトにコンテキストを埋め込む\n","\n","インデックス構造:\n","\n","|インデックス名|\t説明|\n","|-|-|\n","|GPTListIndex|\t単にNodeのリストを保持し，クエリ時は先頭から順次処理し，それぞれの出力を合成|\n","||Node1->Node2->Node3|\n","||ノードをリスト構造で格納するインデックス|\n","|GPTVectorStoreIndex|\t各Nodeに対応する埋め込みベクトルと共に順序付けせずに保持し，埋め込みベクトルを使用してNodeを抽出し，それぞれの出力を合成|\n","||Node1(embedding1)->Node2(embedding2)->Node3(embedding3)|\n","||各ノードと対応する埋め込みをベクトルストアに格納するインデックス|\n","|GPTTreeIndex|\tノードをツリー構造にして保持し，クエリ時はRootから探索して，使用するノードを決め，その出力を合成|\n","||----------Root Node|\n","||-----------------↓|\n","||↓------------------------------↓|\n","||Parent Node1    /            Parent Node2|\n","||↓-----------↓-----------↓----------↓|\n","||Node1/ Node2/ Node3/ Node4|\n","||一連のノードで階層ツリーを構築するインデックス|\n","|GPTKeywordTableIndex|\t各Nodeからキーワードを抽出し，キーワードに対するNodeをマッピングして保持し，クエリ時はクエリのキーワードを使ってNodeを選択し，それぞれのノードの出力を合成|\n","||NYC,City,Population,Climate,Politics->Node1|\n","||NYC,City,Population,Climate,Politics->Node2|\n","||NYC,City,Population,Climate,Politics->Node3|\n","||各ノードからキーワードを選出し、各キーワードから対応するノードへのリンクを構築するインデックス|\n","\n","対応する情報の形式:\n","\n","        PDF、ePub Word PowerPoint Audio\n","\n","対応するWebサービス指定:\n","\n","        Twitter Slack Wikipedia"],"metadata":{"id":"T4T6dpA_WQvU"}},{"cell_type":"markdown","source":["## LlamaIndexによる質問応答の実践例"],"metadata":{"id":"U2xF_GRz_n9Z"}},{"cell_type":"markdown","source":["### LlamaIndexの前準備"],"metadata":{"id":"ifRgZdDP-Wwq"}},{"cell_type":"code","source":["!pip install -q llama-index\n","!pip install -q openai\n","!pip install -q transformers\n","!pip install -q accelerate"],"metadata":{"id":"Rb3_JMNfIoXR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695609071109,"user_tz":-540,"elapsed":39340,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"26b60fd6-ccdc-49ac-fa00-82ecd0b543f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.7/829.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = \"your API key\""],"metadata":{"id":"QgpyVXoIIqki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.llms import OpenAI\n","from llama_index import VectorStoreIndex, SimpleDirectoryReader\n","from IPython.display import Markdown, display"],"metadata":{"id":"ujASWKPEIr_6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### GitHubによるファイルをアップロード"],"metadata":{"id":"WtiBtarBDhaA"}},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin1.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin2.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin3.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin4.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin5.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin6.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin7.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VoQ3yGXKL9Mw","executionInfo":{"status":"ok","timestamp":1695609446828,"user_tz":-540,"elapsed":1825,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"131f860e-dbff-4e0c-a70f-35be3ee796cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-09-25 02:37:25--  https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin1.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 669 [text/plain]\n","Saving to: ‘akazukin1.txt’\n","\n","\rakazukin1.txt         0%[                    ]       0  --.-KB/s               \rakazukin1.txt       100%[===================>]     669  --.-KB/s    in 0s      \n","\n","2023-09-25 02:37:25 (41.1 MB/s) - ‘akazukin1.txt’ saved [669/669]\n","\n","--2023-09-25 02:37:25--  https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin2.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 445 [text/plain]\n","Saving to: ‘akazukin2.txt’\n","\n","akazukin2.txt       100%[===================>]     445  --.-KB/s    in 0s      \n","\n","2023-09-25 02:37:25 (31.7 MB/s) - ‘akazukin2.txt’ saved [445/445]\n","\n","--2023-09-25 02:37:25--  https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin3.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 684 [text/plain]\n","Saving to: ‘akazukin3.txt’\n","\n","akazukin3.txt       100%[===================>]     684  --.-KB/s    in 0s      \n","\n","2023-09-25 02:37:25 (50.1 MB/s) - ‘akazukin3.txt’ saved [684/684]\n","\n","--2023-09-25 02:37:25--  https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin4.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 529 [text/plain]\n","Saving to: ‘akazukin4.txt’\n","\n","akazukin4.txt       100%[===================>]     529  --.-KB/s    in 0s      \n","\n","2023-09-25 02:37:26 (40.2 MB/s) - ‘akazukin4.txt’ saved [529/529]\n","\n","--2023-09-25 02:37:26--  https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin5.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 424 [text/plain]\n","Saving to: ‘akazukin5.txt’\n","\n","akazukin5.txt       100%[===================>]     424  --.-KB/s    in 0s      \n","\n","2023-09-25 02:37:26 (31.7 MB/s) - ‘akazukin5.txt’ saved [424/424]\n","\n","--2023-09-25 02:37:26--  https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin6.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 349 [text/plain]\n","Saving to: ‘akazukin6.txt’\n","\n","akazukin6.txt       100%[===================>]     349  --.-KB/s    in 0s      \n","\n","2023-09-25 02:37:26 (10.6 MB/s) - ‘akazukin6.txt’ saved [349/349]\n","\n","--2023-09-25 02:37:26--  https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin7.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 475 [text/plain]\n","Saving to: ‘akazukin7.txt’\n","\n","akazukin7.txt       100%[===================>]     475  --.-KB/s    in 0s      \n","\n","2023-09-25 02:37:26 (31.8 MB/s) - ‘akazukin7.txt’ saved [475/475]\n","\n"]}]},{"cell_type":"markdown","source":["#### 書類の読み込み表示して質問文章を取得してください。"],"metadata":{"id":"sId3hiytLI2q"}},{"cell_type":"code","source":["file_path = \"/content/data/akazukin1.txt\"\n","\n","try:\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        document = file.read()\n","    print(document)\n","except FileNotFoundError:\n","    print(f\"File not found: {file_path}\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxhQI1C2_Kpa","executionInfo":{"status":"ok","timestamp":1695610280545,"user_tz":-540,"elapsed":219,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"7aa8d658-42b2-45bf-a324-6edc146be28d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["第1章：データフロント\n","\n","夜の煌びやかなネオ東京。高層ビルが連なり、ネオンが街を彩る。その街で、赤いフードをかぶった少女・ミコは、違法なデータカウリアを運ぶ配達員として働いていた。彼女は母親が病に倒れ、その治療費を稼ぐためにデータカウリアに身を投じていた。\n","\n","ある日、ミコは重要なデータを運ぶ任務を受ける。そのデータは、巨大企業「ウルフ・コーポレーション」による市民への悪辣な支配を暴く情報が詰まっていた。彼女はデータを受け取り、目的地へ向かうことに。\n","\n"]}]},{"cell_type":"code","source":["!pip install pypdf"],"metadata":{"id":"2hKe0wFtItdU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["documents = SimpleDirectoryReader(\"data\").load_data()"],"metadata":{"id":"o9FopqQPIus0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index = VectorStoreIndex.from_documents(documents)"],"metadata":{"id":"OxuP2gaoIv4k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695609525416,"user_tz":-540,"elapsed":3193,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"1e114b5f-f3bf-47ab-b6e1-9b03d41ddf2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /tmp/llama_index...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"markdown","source":["クエリエンジンの作成\n","\n","クエリエンジン:\n","\n","ユーザー入力に関する情報をインデックスから取得し、ユーザー入力と取得した情報をもとに、応答を生成するエンジン"],"metadata":{"id":"TS11P-dpLYbN"}},{"cell_type":"code","source":["query_engine = index.as_query_engine()\n"],"metadata":{"id":"xszdH8G2Iw5w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["出力命令"],"metadata":{"id":"AdyHXapRL-As"}},{"cell_type":"code","source":["from llama_index import LlamaIndex\n","\n","# LlamaIndexのインスタンスを作成\n","index = LlamaIndex(model_name=\"text-embedding-ada-002\")\n","\n","# クエリエンジンを作成\n","query_engine = index.get_query_engine()\n","\n","# 質問応答\n","response = query_engine.query(\"ウルフ・コーポレーションは？\")\n","print(response)"],"metadata":{"id":"kPetFQeppGjv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 質問応答\n","print(query_engine.query(\"リョウはだれの友たちですか？\"))"],"metadata":{"id":"HZp8oMV9pPKy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Llamaを使った質問応答"],"metadata":{"id":"-pOooTju-bxH"}},{"cell_type":"code","source":["response = query_engine.query(\"あかずきんさんはどんな人ですか? \")"],"metadata":{"id":"hLG_tOtzIyVG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(Markdown(f\"<b>{response}</b>\"))"],"metadata":{"id":"gwPITAU5I1Bm","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1695609568826,"user_tz":-540,"elapsed":249,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"4708ab5d-8ee4-4236-ef87-141ad70591cc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"<b>赤ずきんさんはデータカウリアと呼ばれる少女で、赤いフードをかぶっていることが特徴です。彼女は違法なデータカウリアとして働いており、母親の治療費を稼ぐためにデータを運んでいます。彼女はウルフ・コーポレーションのエージェントに追われることもありますが、狡猾に彼らを撒いて目的地にたどり着くことができます。</b>"},"metadata":{}}]},{"cell_type":"code","source":["index.storage_context.persist()"],"metadata":{"id":"G0DQidzJI4--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index import StorageContext, load_index_from_storage\n","\n","storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n","index = load_index_from_storage(storage_context=storage_context)"],"metadata":{"id":"lHudFACEI6dW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index import ServiceContext, set_global_service_context\n"],"metadata":{"id":"tgXIoXzLJBdx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define LLM: https://gpt-index.readthedocs.io/en/latest/core_modules/model_modules/llms/usage_custom.html\n","llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0, max_tokens=256)\n","\n","# configure service context\n","service_context = ServiceContext.from_defaults(llm=llm, chunk_size=800, chunk_overlap=20)\n","# set_global_service_context(service_context)\n","index = VectorStoreIndex.from_documents(documents, service_context=service_context)"],"metadata":{"id":"SvlUXyuaJCzf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query_engine = index.as_query_engine(streaming=True)\n","response = query_engine.query(\"あかずきんさんの友達はいますか?\")\n","response.print_response_stream()"],"metadata":{"id":"32OgseW7JDe6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695609653268,"user_tz":-540,"elapsed":1428,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"e427978d-9df0-47c7-ef7a-a2a4a7fa922f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["はい、あかずきんさんの友達はいます。"]}]},{"cell_type":"code","source":["query_engine = index.as_chat_engine()\n","response = query_engine.chat(\"あかずきんさんは最後にどうなりましたでしょうか?\")\n","display(Markdown(f\"<b>{response}</b>\"))"],"metadata":{"id":"XPfCFf9AJG6k","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1695609746754,"user_tz":-540,"elapsed":17281,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"0a09acc9-da89-4d72-f9d6-43346b268402"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"<b>あかずきんさんの最後は、ミコとリョウがウルフ・コーポレーションの悪事を公開し、市民たちを解放した後、彼らは互いの過去を許し合い、再び友情を取り戻しました。ミコはデータカウリアを辞め、リョウと共に新たな道へと歩み始め、彼らは未来のネオ東京をより良い街に変えることを誓いました。これにより、電脳赤ずきんの新たな冒険が始まりました。</b>"},"metadata":{}}]},{"cell_type":"markdown","source":["ログレベルの設定:\n","\n","DEBUGに設定する\n","\n","内部処理の詳細がログ出力される\n","\n","出力レベルの定義:\n","\n","|出力レベル|説明|\n","|-|-|\n","|DEBUG|デバッグ用にプロンプトの詳細な情報を出力|\n","|INFO|プロンプトの進行状況や重要なイベントに関する情報の出力|\n","|WARNING|問題が発生し、プログラム実行が断続可能なときの出力|\n","|ERROR|エラー発生ときの出力|\n","\n","ログインマニュアル:\n","\n","https://docs.python.org/ja/3/library/logging.html"],"metadata":{"id":"BNF4dIpnI-xv"}},{"cell_type":"markdown","source":["#### logging.basicConfig()のパラメーター\n","\n","|パラメーター|説明|\n","|-|-|\n","|stream|出力先|\n","|filename|ファイル名|\n","|level|出力レベル|\n","|force|強制的に以前の設定をリセット|"],"metadata":{"id":"KsCZyRcKKOCo"}},{"cell_type":"code","source":["import logging\n","import sys\n","\n","# ログレベルの設定\n","logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)"],"metadata":{"id":"xikXftfS9vV7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LlamaIndexが実行でない場合:代行例"],"metadata":{"id":"0zPECsTBSx9a"}},{"cell_type":"markdown","source":["### Faissを使った質問応答"],"metadata":{"id":"Utp5yK4bSyrt"}},{"cell_type":"markdown","source":["インストール"],"metadata":{"id":"bFBcLySASyru"}},{"cell_type":"code","source":[" #パッケージのインストール\n","!pip install faiss-gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693542726670,"user_tz":-540,"elapsed":9659,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"289f03fa-fb5d-4238-d62d-f64157bee5da","id":"EVUvNdAMSyru"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n"]}]},{"cell_type":"markdown","source":["インデックスの作成"],"metadata":{"id":"3JQK_V1DSyrw"}},{"cell_type":"code","source":["import faiss\n","\n","# faissのインデックスの作成\n","faiss_index = faiss.IndexFlatL2(1536)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693544830586,"user_tz":-540,"elapsed":415,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"3a0bd13f-fbf5-40f0-87ed-5d5b33fe1728","id":"dPGfpvjcSyrw"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:faiss.loader:Loading faiss with AVX2 support.\n","INFO:faiss.loader:Could not load library with AVX2 support due to:\n","ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n","INFO:faiss.loader:Loading faiss.\n","INFO:faiss.loader:Successfully loaded faiss.\n"]}]},{"cell_type":"markdown","source":["クエリエンジンの作成\n","\n","クエリエンジン:\n","\n","ユーザー入力に関する情報をインデックスから取得し、ユーザー入力と取得した情報をもとに、応答を生成するエンジン"],"metadata":{"id":"tEaI8UKESyrw"}},{"cell_type":"code","source":["import numpy as np\n","import faiss\n","\n","# Download the text files\n","# !wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin1.txt\n","# !wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin2.txt\n","# !wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin3.txt\n","# !wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin4.txt\n","# !wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin5.txt\n","# !wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin6.txt\n","# !wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin7.txt\n","# Download other files similarly\n","\n","# Load the content of the text files into the 'documents' list\n","documents = []\n","for file_name in [\"akazukin1.txt\", \"akazukin2.txt\", \"akazukin3.txt\", \"akazukin4.txt\", \"akazukin5.txt\", \"akazukin6.txt\", \"akazukin7.txt\"]:\n","    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n","        content = file.read()\n","        documents.append(content)\n","\n","# Tokenize and encode documents using a pre-trained model (e.g., BERT)\n","# Replace this with your actual tokenization and encoding process\n","EMBEDDING_DIM = 768  # Replace with the actual embedding dimension\n","document_embeddings = np.random.rand(len(documents), EMBEDDING_DIM)\n","\n","# Normalize embeddings (L2 normalization)\n","normalized_embeddings = document_embeddings / np.linalg.norm(document_embeddings, axis=1, keepdims=True)\n","\n","# Convert the array to float32\n","normalized_embeddings = normalized_embeddings.astype('float32')\n","\n","# Create an index\n","d = normalized_embeddings.shape[1]  # Dimension of embeddings\n","num_clusters = 7  # Number of clusters for IVF index\n","base_index = faiss.IndexFlatIP(d)  # Base index for inner product search\n","index = faiss.IndexIVFFlat(base_index, d, num_clusters, faiss.METRIC_INNER_PRODUCT)\n","\n","# Train the index\n","index.train(normalized_embeddings)\n","index.add(normalized_embeddings)\n","\n","# Define a query embedding\n","query_embedding = np.random.rand(d).astype('float32')\n","faiss.normalize_L2(np.expand_dims(query_embedding, axis=0))\n","\n","\n","# Perform a k-nearest neighbors search\n","k = 5  # Number of nearest neighbors to retrieve\n","D, I = index.search(query_embedding.reshape(1, -1), k)\n","\n","# Print the nearest neighbors and their distances\n","for i in range(k):\n","    print(f\"Nearest Neighbor {i + 1}: Index {I[0][i]}, Distance {D[0][i]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693547167082,"user_tz":-540,"elapsed":3,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"a3f4f81f-2519-4a01-8342-b5607f574f64","id":"34tg8oR_Syrw"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Nearest Neighbor 1: Index 6, Distance 0.7701665759086609\n","Nearest Neighbor 2: Index -1, Distance -3.4028234663852886e+38\n","Nearest Neighbor 3: Index -1, Distance -3.4028234663852886e+38\n","Nearest Neighbor 4: Index -1, Distance -3.4028234663852886e+38\n","Nearest Neighbor 5: Index -1, Distance -3.4028234663852886e+38\n"]}]},{"cell_type":"markdown","source":["出力命令"],"metadata":{"id":"4p2QdWaRSyrx"}},{"cell_type":"code","source":["import numpy as np\n","import faiss\n","\n","# Assume you have already loaded and processed your document data\n","# and have the 'index' ready to use\n","\n","# Define a keyword embedding\n","keyword = \"夜の煌びやかなネオ東京。\"  # Replace with your keyword\n","keyword_embedding = np.random.rand(d).astype('float32')  # Replace with actual keyword embedding\n","\n","# Normalize the keyword embedding\n","faiss.normalize_L2(np.expand_dims(query_embedding, axis=0))\n","\n","# Perform a k-nearest neighbors search for the keyword embedding\n","k = 5  # Number of nearest neighbors to retrieve\n","D, I = index.search(keyword_embedding.reshape(1, -1), k)\n","\n","# Print the documents related to the nearest neighbors\n","for i in range(k):\n","    document_index = I[0][i]\n","    print(f\"Nearest Neighbor {i + 1}: Document {document_index}, Distance {D[0][i]}\")\n","    print(documents[document_index])\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693547376515,"user_tz":-540,"elapsed":3,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"8c36cc34-c25d-4824-f4d4-50a7b6373816","id":"vR43qfTQSyrx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Nearest Neighbor 1: Document 0, Distance 11.960553169250488\n","第1章：データフロント\n","\n","夜の煌びやかなネオ東京。高層ビルが連なり、ネオンが街を彩る。その街で、赤いフードをかぶった少女・ミコは、違法なデータカウリアを運ぶ配達員として働いていた。彼女は母親が病に倒れ、その治療費を稼ぐためにデータカウリアに身を投じていた。\n","\n","ある日、ミコは重要なデータを運ぶ任務を受ける。そのデータは、巨大企業「ウルフ・コーポレーション」による市民への悪辣な支配を暴く情報が詰まっていた。彼女はデータを受け取り、目的地へ向かうことに。\n","\n","\n","Nearest Neighbor 2: Document -1, Distance -3.4028234663852886e+38\n","第7章：新たなる旅立ち\n","\n","ウルフ・コーポレーションの崩壊後、ミコとリョウは互いの過去を許し合い、再び友情を取り戻す。ミコはデータカウリアを辞め、リョウと共に新たな道へと歩み始める。彼らは自らの力を使い、未来のネオ東京をより良い街に変えていくことを誓う。これはミコとリョウ、そして電脳赤ずきんの新たな冒険の幕開けであった。\n","\n","\n","Nearest Neighbor 3: Document -1, Distance -3.4028234663852886e+38\n","第7章：新たなる旅立ち\n","\n","ウルフ・コーポレーションの崩壊後、ミコとリョウは互いの過去を許し合い、再び友情を取り戻す。ミコはデータカウリアを辞め、リョウと共に新たな道へと歩み始める。彼らは自らの力を使い、未来のネオ東京をより良い街に変えていくことを誓う。これはミコとリョウ、そして電脳赤ずきんの新たな冒険の幕開けであった。\n","\n","\n","Nearest Neighbor 4: Document -1, Distance -3.4028234663852886e+38\n","第7章：新たなる旅立ち\n","\n","ウルフ・コーポレーションの崩壊後、ミコとリョウは互いの過去を許し合い、再び友情を取り戻す。ミコはデータカウリアを辞め、リョウと共に新たな道へと歩み始める。彼らは自らの力を使い、未来のネオ東京をより良い街に変えていくことを誓う。これはミコとリョウ、そして電脳赤ずきんの新たな冒険の幕開けであった。\n","\n","\n","Nearest Neighbor 5: Document -1, Distance -3.4028234663852886e+38\n","第7章：新たなる旅立ち\n","\n","ウルフ・コーポレーションの崩壊後、ミコとリョウは互いの過去を許し合い、再び友情を取り戻す。ミコはデータカウリアを辞め、リョウと共に新たな道へと歩み始める。彼らは自らの力を使い、未来のネオ東京をより良い街に変えていくことを誓う。これはミコとリョウ、そして電脳赤ずきんの新たな冒険の幕開けであった。\n","\n","\n"]}]},{"cell_type":"markdown","source":["### Llama: Pineconeを使った質問応答"],"metadata":{"id":"0GpgfnOV-pJy"}},{"cell_type":"markdown","source":["インストール"],"metadata":{"id":"7o6wIuevNV60"}},{"cell_type":"code","source":["# パッケージのインストール\n","!pip install pinecone-client\n","!pip install transformers"],"metadata":{"id":"fXx2CrCz-l4x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["書類の読み込み"],"metadata":{"id":"VRBWtKr7NXuu"}},{"cell_type":"code","source":["from llama_index import SimpleDirectoryReader\n","\n","# ドキュメントの読み込み (dataフォルダにドキュメントを配置しておきます)\n","documents = SimpleDirectoryReader(\"data\").load_data()"],"metadata":{"id":"99mnd3B_-r7a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["クライアント・インデックスを作成"],"metadata":{"id":"9xt7akqHNaaf"}},{"cell_type":"code","source":["import pinecone\n","\n","# pinecone-clientのインデックスの生成\n","api_key = \"<PineconeのAPIキー>\"\n","pinecone.init(api_key=api_key, environment=\"us-west1-gcp\")\n","pinecone.create_index(\n","    \"quickstart\",\n","    dimension=1536,\n","    metric=\"dotproduct\",\n","    pod_type=\"p1\"\n",")\n","pinecone_index = pinecone.Index(\"quickstart\")"],"metadata":{"id":"VacqN3xB-r5W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["インデックスを作成"],"metadata":{"id":"7J5VNSGMNpnn"}},{"cell_type":"code","source":["from llama_index import GPTVectorStoreIndex, StorageContext\n","from llama_index.vector_stores.pinecone import PineconeVectorStore\n","\n","# インデックスの作成\n","vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n","storage_context = StorageContext.from_defaults(vector_store=vector_store)\n","index = GPTVectorStoreIndex.from_documents(\n","    documents,\n","    storage_context=storage_context\n",")"],"metadata":{"id":"AqL_ZEGj-r2s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["クエリエンジンを作成"],"metadata":{"id":"RD-OWqbNNt_a"}},{"cell_type":"code","source":["# クエリエンジンの作成\n","query_engine = index.as_query_engine()"],"metadata":{"id":"8TleUDOh-r0L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["出力命令"],"metadata":{"id":"wM4Mbtp0NxZb"}},{"cell_type":"code","source":["# 質問応答\n","print(query_engine.query(\"ミコの幼馴染の名前は？\"))"],"metadata":{"id":"HyT66HVP-rxp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["インデックスの保存および読み込み"],"metadata":{"id":"gB8anQ6OMOa8"}},{"cell_type":"code","source":["index.storage_context.persist()"],"metadata":{"id":"wAyz9aimMTj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index import StorageContext, load_index_from_storage\n","\n","storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n","index = load_index_from_storage(storage_comtext)"],"metadata":{"id":"odgOS1oZMeuS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LlamaIndexが実行でない場合:代行例"],"metadata":{"id":"FZs4fTjvUliz"}},{"cell_type":"markdown","source":["### Faiss: Pineconeを使った質問応答"],"metadata":{"id":"KLEINQ0aUl3a"}},{"cell_type":"markdown","source":["インストール"],"metadata":{"id":"7GeyeFDIUl3a"}},{"cell_type":"code","source":["# パッケージのインストール\n","!pip install pinecone-client\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PKCzMtaqUl3b","executionInfo":{"status":"ok","timestamp":1693547969637,"user_tz":-540,"elapsed":16848,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"e3953c26-42c8-4d4f-a71c-77d61e3e63aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pinecone-client\n","  Downloading pinecone_client-2.2.2-py3-none-any.whl (179 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/179.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0.1)\n","Collecting loguru>=0.5.0 (from pinecone-client)\n","  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.7.1)\n","Collecting dnspython>=2.0.0 (from pinecone-client)\n","  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n","Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.4)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.1)\n","Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.23.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.7.22)\n","Installing collected packages: loguru, dnspython, pinecone-client\n","Successfully installed dnspython-2.4.2 loguru-0.7.0 pinecone-client-2.2.2\n","Collecting transformers\n","  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"]}]},{"cell_type":"markdown","source":["書類の読み込み"],"metadata":{"id":"S8L7roE6Ul3b"}},{"cell_type":"markdown","source":["クライアント・インデックスを作成"],"metadata":{"id":"4xJvCyXdUl3b"}},{"cell_type":"markdown","source":["インデックスを作成"],"metadata":{"id":"FIQ58gl-Ul3b"}},{"cell_type":"code","source":["import pinecone\n","import numpy as np\n","\n","# Initialize the Pinecone client with your API key\n","pinecone.init(api_key=\"your_API_key\")\n","\n","# Define the index name and embedding dimension\n","index_name = \"my-index\"\n","EMBEDDING_DIM = 768  # Replace with your actual embedding dimension\n","\n","# Create an index with the specified dimension\n","pinecone.create_index(index_name, dimension=EMBEDDING_DIM)\n","\n","# Generate some example embeddings and IDs (replace with your actual data)\n","num_embeddings = 1000\n","embeddings = np.random.rand(num_embeddings, EMBEDDING_DIM).astype('float32')\n","ids = [str(i) for i in range(num_embeddings)]\n","\n","# Upload the embeddings and IDs to the index\n","pinecone_index = pinecone.Index(index_name=index_name)\n","pinecone_index.upsert(ids, embeddings)\n","\n","# Define a query embedding (replace with your query)\n","query_embedding = np.random.rand(EMBEDDING_DIM).astype('float32')\n","\n","# Perform a similarity search\n","top_k = 5  # Number of nearest neighbors to retrieve\n","results = pinecone_index.query(queries=[query_embedding], top_k=top_k)\n","\n","# Print the results\n","for i, (query_id, neighbors) in enumerate(results.items()):\n","    print(f\"Query {i + 1} - Nearest Neighbors for ID {query_id}:\")\n","    for neighbor_id, score in neighbors:\n","        print(f\"Neighbor ID: {neighbor_id}, Score: {score}\")"],"metadata":{"id":"U4ZXqY8uVCBY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["クエリエンジンを作成"],"metadata":{"id":"SFtTATMhUl3b"}},{"cell_type":"code","source":["import pinecone\n","import numpy as np\n","\n","# Initialize the Pinecone client with your API key\n","pinecone.init(api_key=\"your_API_key\")\n","\n","# Define the index name and embedding dimension\n","index_name = \"my-index\"\n","EMBEDDING_DIM = 768  # Replace with your actual embedding dimension\n","\n","# Load the content of the \"akazukin.txt\" document\n","with open(\"akazukin.txt\", \"r\", encoding=\"utf-8\") as file:\n","    query_text = file.read()\n","\n","# Tokenize and encode the query text using a pre-trained model (e.g., BERT)\n","# Replace this with your actual tokenization and encoding process\n","query_embedding = np.random.rand(EMBEDDING_DIM).astype('float32')\n","\n","# Create an index with the specified dimension (if it doesn't exist)\n","if not pinecone.Index.exists(index_name):\n","    pinecone.create_index(index_name, dimension=EMBEDDING_DIM)\n","\n","# Upload the query embedding to the index with an associated ID\n","pinecone_index = pinecone.Index(index_name=index_name)\n","query_id = \"query_1\"  # Replace with a suitable ID for your query\n","pinecone_index.upsert(ids=[query_id], embeddings=[query_embedding])\n","\n","# Perform a similarity search\n","top_k = 5  # Number of nearest neighbors to retrieve\n","results = pinecone_index.query(queries=[query_embedding], top_k=top_k)\n","\n","# Print the results\n","print(\"Nearest Neighbors for the Query:\")\n","for neighbor_id, score in results[query_id]:\n","    print(f\"Neighbor ID: {neighbor_id}, Score: {score}\")"],"metadata":{"id":"WNzIjhzKWBsC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["出力命令"],"metadata":{"id":"dY4OS0yvUl3c"}},{"cell_type":"code","source":["import pinecone\n","import numpy as np\n","\n","# Initialize the Pinecone client with your API key\n","pinecone.init(api_key=\"YOUR_API_KEY\")\n","\n","# Define the index name and embedding dimension\n","index_name = \"my-index\"\n","EMBEDDING_DIM = 768  # Replace with your actual embedding dimension\n","\n","# Create a Pinecone index if it doesn't exist\n","if not pinecone.Index.exists(index_name):\n","    pinecone.create_index(index_name, dimension=EMBEDDING_DIM)\n","\n","# Function to perform a similarity search based on a user's question\n","def perform_similarity_search(question_text, top_k=5):\n","    # Tokenize and encode the user's question using a pre-trained model (e.g., BERT)\n","    # Replace this with your actual tokenization and encoding process\n","    question_embedding = np.random.rand(EMBEDDING_DIM).astype('float32')\n","\n","    # Upload the question embedding to the Pinecone index with a unique ID\n","    question_id = \"user_query\"  # Use a unique ID for the user's question\n","    pinecone_index = pinecone.Index(index_name=index_name)\n","    pinecone_index.upsert(ids=[question_id], embeddings=[question_embedding])\n","\n","    # Perform a similarity search\n","    results = pinecone_index.query(queries=[question_embedding], top_k=top_k)\n","\n","    # Extract and return the IDs of the nearest neighbors\n","    neighbor_ids = [neighbor_id for neighbor_id, _ in results[question_id]]\n","    return neighbor_ids\n","\n","# Example usage:\n","user_question = \"ミコの幼馴染の名前は？\"\n","nearest_neighbors = perform_similarity_search(user_question)\n","print(\"Nearest Neighbors IDs:\", nearest_neighbors)"],"metadata":{"id":"OebA0grrWfQy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["インデックスの保存および読み込み"],"metadata":{"id":"98GBVsrlUl3c"}},{"cell_type":"code","source":["import faiss\n","\n","# Your Faiss index (already trained and ready)\n","index = faiss.IndexFlatIP(d)  # Replace 'd' with your actual embedding dimension\n","\n","# File path to save the index\n","index_filename = \"my_faiss_index.index\"\n","\n","# Save the index\n","faiss.write_index(index, index_filename)"],"metadata":{"id":"0eLCA_dvXPfD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import faiss\n","\n","# File path where the index was saved\n","index_filename = \"my_faiss_index.index\"\n","\n","# Load the index\n","loaded_index = faiss.read_index(index_filename)\n"],"metadata":{"id":"MfJJ0xN4XQol"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LlamaIndexの機能詳細"],"metadata":{"id":"M4jCV8ZkM5aV"}},{"cell_type":"markdown","source":["### LlamaIndexの作成手順\n","\n","* ドキュメントの読み込み\n","\n","* インデックスの作成\n","\n","* クエリエンジンの作成\n","\n","* 質問応答"],"metadata":{"id":"vL-Jx8F6N31F"}},{"cell_type":"markdown","source":["### Hugging Faceの登録準備\n","\n","* Hugging Face\n","\n","機械学習アプリケーション開発企業\n","\n","Hugging Face公式サイト:\n","\n","https://huggingface.co\n","\n","「transformers」や画像生成のモデルを共通インターフェースで利用できる「diffusers」などのライブラリを提供する\n","\n","機械学習モデルやデータセット「Hugging Face Hubを通してデータセットを提供する」を共有するプラットフォーム\n","\n","<figure>\n","<a href=\"https://ai.meta.com/llama/\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.10.png' alt='Meta AIのLlaMA2の学習パラメーター数' width='25%' border='1'></a>\n","</figure>\n","\n","<!-- <img src=\"https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2022/09/hugging-face-eyecatch-960x504.png\n","\" alt=\"参考図：Class Methodより\"> -->\n","\n","図5.10. 出所: Class Method公式Webサイト |Hugging Face企業のロゴ\n","\n","\n","\n","\n"],"metadata":{"id":"bxF_QbSxO8Rj"}},{"cell_type":"markdown","source":["### LlamaIndexの前準備"],"metadata":{"id":"44zumFBQRvHM"}},{"cell_type":"markdown","source":["#### Hugging Faceモデルを使うためGPUを有効する"],"metadata":{"id":"d6VVEEpPf52F"}},{"cell_type":"code","source":["from llama_index import SimpleDirectoryReader\n","\n","# ドキュメントの読み込み (dataフォルダにドキュメントを配置しておきます)\n","documents = SimpleDirectoryReader(\"data\").load_data()\n","print(\"document :\", documents)"],"metadata":{"id":"BSlqHV_0RgF9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####ドキュメントを手動で作成"],"metadata":{"id":"u4ZrUZiETLRz"}},{"cell_type":"code","source":["from llama_index import Document\n","\n","texts = [\"text1\",\"text2\",\"text3\"]\n","documents = [Document(t) for t in texts]\n","print(\"document :\", documents)"],"metadata":{"id":"OKnrDsaZRgBE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### インデックスの作成"],"metadata":{"id":"IRMMmU_qTxx9"}},{"cell_type":"code","source":["from llama_index import GPTVectorStoreIndex\n","\n","index = GPTVectorStoreIndex.from_documents(documents)"],"metadata":{"id":"X4GwDW7aRf-Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### インデックスへのドキュメントの挿入"],"metadata":{"id":"XnXdCzieXJ7Z"}},{"cell_type":"code","source":["from llama_index import GPTVectorStoreIndex\n","\n","index = GPTVectorStoreIndex([])\n","\n","for doc in documents:\n","    index.insert(doc)"],"metadata":{"id":"C_Slu4WKRfzS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### インデックスのカスタマイズ\n","\n","prompt_helper:チャンク分割ルールのカスタマイズ\n","\n","        max_input_size:LLM入力の最大トークン数\n","\n","        num_output:LLM出力のトークン数\n","\n","        max_chunck_overlap:チャンクオーバーラップの最大トークン数\n","\n","embed_model:埋め込みモデルのカスタマイズ\n","\n","llm_predictor:使用するLLMのカスタマイズ\n","\n","        llmはLangChainのLLMクラスを継承して指定する\n","\n","Integrations-LangChain\n","\n","https://python.langchain.com/en/latest/modules/llms/integrations.html\n","\n","\n","\n"],"metadata":{"id":"AlEdPa9ibS4e"}},{"cell_type":"markdown","source":["#### 使用するLLMのカスタマイズ\n","\n","デフォルトの「text-davinci-003」を「gpt-3.5-turbo」に変えることでトークン利用数が安くなる"],"metadata":{"id":"To2vOskJYdu5"}},{"cell_type":"code","source":["from llama_index import LLMPredictor, ServiceContext\n","from langchain.chat_models import ChatOpenAI\n","\n","# LLMPredictorの準備\n","llm_predictor = LLMPredictor(llm=ChatOpenAI(\n","    temperature=0,  # 温度\n","    model_name=\"gpt-3.5-turbo\" # モデル目\n","))\n","\n","# ServiceContextの準備\n","service_context = ServiceContext.from_defaults(\n","    llm_predictor=llm_predictor,\n",")\n","\n","# インデックスの生成\n","index = GPTVectorStoreIndex.from_documents(\n","    documents,\n","    service_context=service_context,\n",")"],"metadata":{"id":"nT1NgRtuYIi7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### チャンク分割ルールのカスタマイズ"],"metadata":{"id":"_8kZ_QTaYibM"}},{"cell_type":"code","source":["from llama_index import GPTVectorStoreIndex, PromptHelper, ServiceContext\n","\n","# PromptHelperの準備\n","prompt_helper=PromptHelper(\n","    max_input_size=4096,  # LLM入力の最大トークン数\n","    num_output=256,  # LLM出力のトークン数\n","    max_chunk_overlap=20,  # チャンクオーバーラップの最大トークン数\n",")\n","\n","# ServiceContextの準備\n","service_context = ServiceContext.from_defaults(\n","    prompt_helper=prompt_helper\n",")\n","\n","# インデックスの生成\n","index = GPTVectorStoreIndex.from_documents(\n","    documents,\n","    service_context=service_context,\n",")"],"metadata":{"id":"4KVFdI9XYIgO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LangChainEmbeddingの準備"],"metadata":{"id":"0MoeA1-9eDzK"}},{"cell_type":"markdown","source":["#### 埋め込みモデルのカスタマイズ\n","\n","\n","デフォルトの「text-embedding-ada-002」を「Hugging Face」に変えることで無料化できる"],"metadata":{"id":"n_l8qSJTYmfJ"}},{"cell_type":"markdown","source":["#### Hugging Faceの埋め込みモデル実行パッケージをインストール"],"metadata":{"id":"I2wLydyZeCgG"}},{"cell_type":"code","source":["# sentence_transformersパッケージのインストール\n","!pip install sentence_transformers"],"metadata":{"id":"FAX2kI8yYIQ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Hugging Face embeddingモデルの定義\n","\n","oshizo/sbert-jsnli-luke-japanese-base-lite\n","\n","https://huggingface.co/oshizo/sbert-jsnli-like-japanese-base-lite\n","\n","基本的にデフォルト設定のままで使える、変更したい理由がない限りカスタマイズをする必要はない"],"metadata":{"id":"BtFnk8u9jyKQ"}},{"cell_type":"code","source":["from langchain.embeddings import HuggingFaceEmbeddings\n","from llama_index import GPTVectorStoreIndex, ServiceContext, LangchainEmbedding\n","\n","# 埋め込みモデルの準備\n","embed_model = LangchainEmbedding(HuggingFaceEmbeddings(\n","    model_name=\"oshizo/sbert-jsnli-luke-japanese-base-lite\"\n","))\n","\n","# ServiceContextの準備\n","service_context = ServiceContext.from_defaults(\n","    embed_model=embed_model\n",")\n","\n","# インデックスの生成\n","index = GPTVectorStoreIndex.from_documents(\n","    documents, # ドキュメント\n","    service_context=service_context, # ServiceContext\n",")"],"metadata":{"id":"DpZOnCCTYINW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### クエリエンジンの作成\n","\n","エンジン名:\n","\n","index.as_query_engine()\n","\n","このエンジン利用にはAPIを使う必要がある\n","\n","LlamaIndex 利用ガイダンス\n","\n","https://gpt-index.readthedocs.io/en/latest/core_modules/query_modules/query_engine/root.html"],"metadata":{"id":"QirpYzMgeG9I"}},{"cell_type":"code","source":["# クエリエンジンの作成\n","query_engine = index.as_query_engine()"],"metadata":{"id":"pnGKGHiyYIJv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 質問応答の実行"],"metadata":{"id":"s3nv5x2OeL2K"}},{"cell_type":"code","source":["# 質問応答\n","response = query_engine.query(\"ミコの幼馴染の名前は？\")\n","print(response)"],"metadata":{"id":"izTU6AlaYIHD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# レスポンス\n","print(\"response :\", response.response, \"\\n\")\n","\n","# ソース\n","print(\"source_nodes :\", response.source_nodes, \"\\n\")"],"metadata":{"id":"KqgeszqMYUc6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LlamaHub"],"metadata":{"id":"v8w1isVw6zim"}},{"cell_type":"markdown","source":["LlamaIndexの読み込みドキュメントの形式:\n","\n","テキスト、PDF、ePub、Word、PowerPoint、Audioなど\n","\n","Webサービス対応形式:\n","\n","Twitter、Slack、Wikipaediaなど\n","\n","LlamaHub\n","\n","https://llamahub.ai/\n","\n","<figure>\n","<a href=\"https://ai.meta.com/llama/\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.11.png' alt='Meta AIのLlaMA2の学習パラメーター数' width='640' border='1'></a>\n","</figure>\n","\n","<!-- <img src=\"https://user-images.githubusercontent.com/10040285/253985887-5e344de4-4aca-4f6c-9944-46c00baa5eb2.png\" alt=\"参考図:emptycrown\n","/llama-hubPublicより\"> -->\n","\n","図5.11. 出所:emptycrown/llama-hubPublic公式Webサイト |LlamaHubの画面\n","\n"],"metadata":{"id":"vjZMGw48mwBq"}},{"cell_type":"markdown","source":["### LlamaHubのプラグインリスト\n","\n","\n","\n"],"metadata":{"id":"zv3KnDJyq6Bb"}},{"cell_type":"markdown","source":["|プラグイン名|機能|\n","|-|-|\n","|airtable|ExcelやAccessのように表の作成、項目入力、テキスト以外の型を指定、フィルタリング、グルーピング、計算、チェックボックス、ドロップダウンリストなどの項目を挿入、表示形式を変更することができる。\n","||https://nocodedb.world/archives/5340|\n","|asana|管理表のように個人タスク、プロジェクト、サブタスクの追加、タスクの階層化、チャット機能、ブラウザのリロードなしのリアルタイム情報更新、細かな通知設定、様々な形式のファイルのアップ、カレンダー、進行状況のグラフを標準などができる。|\n","||https://asana.com/ja|\n","|azcognitive_search|検索に関連した機能を容易に実装する言語分析またはカスタム テキスト分析をする。 ユーザー定義のプライベートな検索インデックスへの異種コンテンツの統合。インデックス作成とクエリワークロードを専用の検索サービスにオフロード、関連性のチューニング、ファセット ナビゲーション、フィルター (地理空間検索)、同意語マッピング、オートコンプリートなどができる。|\n","||https://qiita.com/nohanaga/items/a8a70bb19cdb2710eb72|\n","|bilibili|中国に本社を置く上海幻電信息科技有限公司（Shanghai Hode Information Technology Co.）が運営している中国の動画共有サイトで、「中国版ニコニコ動画」と称されるライブ配信アプリである\n","||https://pc.moppy.jp/trend/bilibili/|\n","|chatgpt_plugin|ChatGPTだけではできないテキスト表示以外の画像、動画、レシピ集、などさまざまな表示ができる|\n","||https://www.sungrove.co.jp/chatgpt-plugin/|\n","|chroma|高速な検索やクエリ処理を実現するために最適化されたオープンソースの埋め込みデータベースで、知識、事実、スキルをLLM（Language Model）にプラグイン可能にすることで、LLMアプリケーションの構築を容易にする。PythonクライアントSDK、JavaScript/TypeScriptクライアントSDK、およびサーバーアプリケーションが含まれている。|\n","|近傍探索（Nearest Neighbor Search）などの高度な検索アルゴリズムが使用され、大規模なデータセットに対しても効率的な操作が可能|https://asameshicode.com/chromadb/|\n","|confluence|企業向けwikiツールで、オンラインでの共同編集、履歴を残せる（任意の時点に巻き戻し可能）、Markdown対応などができる|\n","||https://qiita.com/aykooo/items/2131fb0bdb393ecb7d96|\n","|couchdb|データベースの設計/構築/操作について極力リラックスできるドキュメント指向データベース環境で、ドキュメントをデータとして管理し、Web公開に最適化されたデータベース管理システムである。|\n","|「RESTful HTTP/JSON API」「スキーマレス(NoSQL)」「分散型」「スケーラブル」「耐障害性」などの特徴|https://www.ossnews.jp/oss_info/Apache_CouchDB|\n","|dad-jokes||\n","|database||\n","|discord||\n","|elasticsearch||\n","|faiss||\n","|feedly_rss||\n","|file||\n","|file/audio||\n","|file/audio_gladia||\n","|file/cjk_pdf||\n","|file/docx||\n","|file/epub||\n","|file/flat_pdf||\n","|file/image||\n","|file/json||\n","|file/markdown||\n","|file/mbox||\n","|file/paged_csv||\n","|file/pandas_csv||\n","|file/pandas_excel||\n","|file/pdf||\n","|file/pptx||\n","|file/rdf||\n","|file/simple_csv||\n","|file/unstructured||\n","|github_repo||\n","|gmail||\n","|google_calendar||\n","|google_docs||\n","|google_drive||\n","|google_sheets||\n","|gpt_repo||\n","|hatena_blog||\n","|intercom||\n","|jira||\n","|jsondata||\n","|make_com||\n","|memos||\n","|milvus||\n","|mongo||\n","|notion||\n","|obsidian||\n","|opendal_reader||\n","|opendal_reader/azblob||\n","|opendal_reader/gcs||\n","|opendal_reader/s3||\n","|papers/arxiv||\n","|papers/pubmed||\n","|pinecone||\n","|qdrant||\n","|readwise||\n","|reddit||\n","|remote||\n","|remote_depth||\n","|s3||\n","|slack||\n","|spotify||\n","|steamship||\n","|string_iterable||\n","|twitter||\n","|weaviate||\n","|web/beautiful_soup_web||\n","|web/knowledge_base||\n","|seb/readability_web||\n","|web/rss||\n","|web/simple_web||\n","|web/unstructured_web||\n","|whatsapp||\n","|wikipaedia||\n","|wordpress||\n","|youtube_transcript||\n","|zendesk||\n"],"metadata":{"id":"LAi11b_aqICo"}},{"cell_type":"markdown","source":["​Llama Hubは、​LlamaIndexや​LangChainと連携してカスタムデータソースを接続するためのデータローダーのリポジトリである\n","\n","Llama Hubにはさまざまなプラグインがあり、データローダーやエージェントツールなどが利用できる\n","\n","ユーザーはLlama Hubを使って独自のデータソースをLlamaIndexやLangChainに接続することができる\n","\n","Llama Hubの​GitHubリポジトリでは、追加されたプラグインやツールの一覧を確認することができる\n","\n","​Discordには、Llama Hubに関するコミュニティがあり、質問や情報交換などが行われている"],"metadata":{"id":"ctI1F6a5nqkH"}},{"cell_type":"markdown","source":["### LlamaIndexの前準備"],"metadata":{"id":"9KHSdSZ0-5Os"}},{"cell_type":"markdown","source":["#### LlamaIndexのパッケージをインストール"],"metadata":{"id":"NiG5Sje32FOB"}},{"cell_type":"code","source":["# パッケージのインストール\n","!pip install llama-index==0.6.12"],"metadata":{"id":"RNKFqfZ123JB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install typing-extensions==4.6.0"],"metadata":{"id":"8f8rj1u525re"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### API環境準備"],"metadata":{"id":"BV6vH3qk2Kyf"}},{"cell_type":"code","source":["# 環境変数の準備\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = \"your_API_key\""],"metadata":{"id":"oBZTvChP-6Zv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ログレベルの設定"],"metadata":{"id":"KqKDE25_2PIr"}},{"cell_type":"code","source":["import logging\n","import sys\n","\n","# ログレベルの設定\n","logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)"],"metadata":{"id":"YKpVaLhy-6XQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Llama:Webページへの質問応答\n","\n","beautifulsoup4 4.12.2\n","\n","https://pypi.org/project/beautifulsoup4/"],"metadata":{"id":"mzg8S3CG_CVP"}},{"cell_type":"markdown","source":["#### ドキュメントの読み込み\n","\n","ドキュメントはURLを使う\n","\n","Planning for AGI and beyond\n","\n","https://openai.com/blog/planning-for-agi-and-beyond"],"metadata":{"id":"ImvQSztx2U4d"}},{"cell_type":"code","source":["import json\n","from urllib.request import urlopen\n","from bs4 import BeautifulSoupWebReader\n","\n","def load_json_from_url(url):\n","    try:\n","        response = urlopen(url)\n","        content = response.read().decode(\"utf-8\")\n","        return json.loads(content)\n","    except json.JSONDecodeError as e:\n","        print(f\"JSON decoding error: {e}\")\n","        print(f\"Content retrieved: {content}\")\n","\n","# Example URL\n","url = \"https://openai.com/blog/planning-for-agi-and-beyond\"\n","\n","# Load the JSON content from the URL\n","json_data = load_json_from_url(url)\n","\n","# Print the JSON data\n","print(json_data)"],"metadata":{"id":"OFGO1OnVmsGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index import download_loader\n","\n","# ドキュメントの読み込み\n","BeautifulSoupWebReader = download_loader(\"BeautifulSoupWebReader\")\n","loader = BeautifulSoupWebReader()\n","documents = loader.load_data(urls=[\"https://openai.com/blog/planning-for-agi-and-beyond\"])"],"metadata":{"id":"Bj4o3_8f-6Ur"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### インデックスの作成"],"metadata":{"id":"QU7Ma_Ub2aTO"}},{"cell_type":"code","source":["from llama_index import GPTVectorStoreIndex\n","\n","# インデックスの作成\n","index = GPTVectorStoreIndex.from_response(url)"],"metadata":{"id":"mKzLQDJD-6R6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### クエリエンジンの作成"],"metadata":{"id":"stbAvXlf2dKN"}},{"cell_type":"code","source":["# クエリエンジンの作成\n","query_engine = index.as_query_engine()"],"metadata":{"id":"HRakptZ4-6PX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 質問応答の命令"],"metadata":{"id":"ur3hBCXQ2gcF"}},{"cell_type":"code","source":["# 質問応答\n","print(query_engine.query(\"There are several things we think are important to do now to prepare for AGI.\"))"],"metadata":{"id":"V6ifX0Mh-6M9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LlamaIndexが実行でない場合:代行例\n","\n","from urllib.request import urlopen\n","\n","from bs4 import BeautifulSoup"],"metadata":{"id":"vj7b8eXD7whT"}},{"cell_type":"markdown","source":["### Faiss: Webページへの質問応答\n","\n","beautifulsoup4 4.12.2\n","\n","https://pypi.org/project/beautifulsoup4/"],"metadata":{"id":"GZunsz9c76wz"}},{"cell_type":"markdown","source":["#### ドキュメントの読み込み\n","\n","ドキュメントはURLを使う\n","\n","Planning for AGI and beyond\n","\n","https://openai.com/blog/planning-for-agi-and-beyond"],"metadata":{"id":"Oy8E0RCG76w0"}},{"cell_type":"code","source":["from urllib.request import urlopen\n","from bs4 import BeautifulSoup\n","\n","# URL of the webpage to scrape\n","url = \"https://openai.com/blog/planning-for-agi-and-beyond\"\n","# documents = loader.load_data(urls=[\"https://openai.com/blog/planning-for-agi-and-beyond\"])\n","\n","# Fetch the HTML content from the webpage\n","response = urlopen(url)\n","html_content = response.read()\n","\n","# Parse the HTML content using BeautifulSoup\n","soup = BeautifulSoup(html_content, \"html.parser\")\n","\n","# Example: Find all <a> tags and print their text content\n","for link in soup.find_all(\"a\"):\n","    print(link.get_text())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693536126513,"user_tz":-540,"elapsed":336,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"f22bedb8-cb9a-42ff-a99f-c92436844c16","id":"xNJI-dUY76w0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Skip to main content\n","\n","Overview\n","Index\n","GPT-4\n","DALL·E 2\n","Overview\n","Data privacy\n","Pricing\n","Docs\n","Overview\n","Enterprise\n","Try ChatGPT\n","Safety\n","About\n","Blog\n","Careers\n","Charter\n","Security\n","Customer stories\n","Log in\n","Get started\n","\n","Safety\n","Log in\n","Get started\n","Sam Altman\n","Safety & Alignment\n","benefits all of humanity\n","existential\n","InstructGPT\n","ChatGPT\n","new alignment techniques\n","use AI to help humans evaluate\n","a clause in our Charter\n","View all articles\n","\n","Overview\n","Index\n","GPT-4\n","DALL·E 2\n","Overview\n","Data privacy\n","Pricing\n","Docs\n","Overview\n","Enterprise\n","Try ChatGPT\n","About\n","Blog\n","Careers\n","Charter\n","Security\n","Customer stories\n","Safety\n","Terms & policies\n","Privacy policy\n","Brand guidelines\n","Twitter\n","YouTube\n","GitHub\n","SoundCloud\n","LinkedIn\n"]}]},{"cell_type":"markdown","source":["#### インデックスの作成"],"metadata":{"id":"hSen9t4s76w0"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","# URL of the webpage to fetch and index\n","url = \"https://openai.com/blog/planning-for-agi-and-beyond\"\n","\n","# Fetch the HTML content from the webpage\n","response = requests.get(url)\n","html_content = response.content\n","\n","# Parse the HTML content using BeautifulSoup\n","soup = BeautifulSoup(html_content, \"html.parser\")\n","\n","# Index the content you're interested in\n","# For example, let's extract and index all <p> tags' text content\n","paragraphs = soup.find_all(\"p\")\n","indexed_content = [p.get_text() for p in paragraphs]\n","\n","# Print the indexed content\n","for idx, content in enumerate(indexed_content, start=1):\n","    print(f\"Index {idx}: {content}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693536546926,"user_tz":-540,"elapsed":565,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"155d12b4-6e3c-40b4-9e4a-c740edc7c810","id":"HzJ5HuXE76w0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): openai.com:443\n","DEBUG:urllib3.connectionpool:https://openai.com:443 \"GET /blog/planning-for-agi-and-beyond HTTP/1.1\" 200 None\n","Index 1: Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity.\n","\n","Index 2: Illustration: Justin Jay Wang × DALL·E\n","\n","Index 3: Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity.\n","\n","Index 4: If AGI is successfully created, this technology could help us elevate humanity by increasing abundance, turbocharging the global economy, and aiding in the discovery of new scientific knowledge that changes the limits of possibility.\n","\n","Index 5: AGI has the potential to give everyone incredible new capabilities; we can imagine a world where all of us have access to help with almost any cognitive task, providing a great force multiplier for human ingenuity and creativity.\n","\n","Index 6: On the other hand, AGI would also come with serious risk of misuse, drastic accidents, and societal disruption. Because the upside of AGI is so great, we do not believe it is possible or desirable for society to stop its development forever; instead, society and the developers of AGI have to figure out how to get it right.[^gifts]\n","\n","Index 7: Although we cannot predict exactly what will happen, and of course our current progress could hit a wall, we can articulate the principles we care about most:\n","\n","Index 8: There are several things we think are important to do now to prepare for AGI.\n","\n","Index 9: First, as we create successively more powerful systems, we want to deploy them and gain experience with operating them in the real world. We believe this is the best way to carefully steward AGI into existence—a gradual transition to a world with AGI is better than a sudden one. We expect powerful AI to make the rate of progress in the world much faster, and we think it’s better to adjust to this incrementally.\n","\n","Index 10: A gradual transition gives people, policymakers, and institutions time to understand what’s happening, personally experience the benefits and downsides of these systems, adapt our economy, and to put regulation in place. It also allows for society and AI to co-evolve, and for people collectively to figure out what they want while the stakes are relatively low.\n","\n","Index 11: We currently believe the best way to successfully navigate AI deployment challenges is with a tight feedback loop of rapid learning and careful iteration. Society will face major questions about what AI systems are allowed to do, how to combat bias, how to deal with job displacement, and more. The optimal decisions will depend on the path the technology takes, and like any new field, most expert predictions have been wrong so far. This makes planning in a vacuum very difficult.[^planning]\n","\n","Index 12: Generally speaking, we think more usage of AI in the world will lead to good, and want to promote it (by putting models in our API, open-sourcing them, etc.). We believe that democratized access will also lead to more and better research, decentralized power, more benefits, and a broader set of people contributing new ideas.\n","\n","Index 13: As our systems get closer to AGI, we are becoming increasingly cautious with the creation and deployment of our models. Our decisions will require much more caution than society usually applies to new technologies, and more caution than many users would like. Some people in the AI field think the risks of AGI (and successor systems) are fictitious; we would be delighted if they turn out to be right, but we are going to operate as if these risks are existential.\n","\n","Index 14: At some point, the balance between the upsides and downsides of deployments (such as empowering malicious actors, creating social and economic disruptions, and accelerating an unsafe race) could shift, in which case we would significantly change our plans around continuous deployment.\n","\n","Index 15: As our systems get closer to AGI, we are becoming increasingly cautious with the creation and deployment of our models.\n","\n","Index 16: Second, we are working towards creating increasingly aligned and steerable models. Our shift from models like the first version of GPT-3 to InstructGPT and ChatGPT is an early example of this.\n","\n","Index 17: In particular, we think it’s important that society agree on extremely wide bounds of how AI can be used, but that within those bounds, individual users have a lot of discretion. Our eventual hope is that the institutions of the world agree on what these wide bounds should be; in the shorter term we plan to run experiments for external input. The institutions of the world will need to be strengthened with additional capabilities and experience to be prepared for complex decisions about AGI.\n","\n","Index 18: The “default setting” of our products will likely be quite constrained, but we plan to make it easy for users to change the behavior of the AI they’re using. We believe in empowering individuals to make their own decisions and the inherent power of diversity of ideas.\n","\n","Index 19: We will need to develop new alignment techniques as our models become more powerful (and tests to understand when our current techniques are failing). Our plan in the shorter term is to use AI to help humans evaluate the outputs of more complex models and monitor complex systems, and in the longer term to use AI to help us come up with new ideas for better alignment techniques.\n","\n","Index 20: Importantly, we think we often have to make progress on AI safety and capabilities together. It’s a false dichotomy to talk about them separately; they are correlated in many ways. Our best safety work has come from working with our most capable models. That said, it’s important that the ratio of safety progress to capability progress increases.\n","\n","Index 21: Third, we hope for a global conversation about three key questions: how to govern these systems, how to fairly distribute the benefits they generate, and how to fairly share access.\n","\n","Index 22: In addition to these three areas, we have attempted to set up our structure in a way that aligns our incentives with a good outcome. We have a clause in our Charter about assisting other organizations to advance safety instead of racing with them in late-stage AGI development. We have a cap on the returns our shareholders can earn so that we aren’t incentivized to attempt to capture value without bound and risk deploying something potentially catastrophically dangerous (and of course as a way to share the benefits with society). We have a nonprofit that governs us and lets us operate for the good of humanity (and can override any for-profit interests), including letting us do things like cancel our equity obligations to shareholders if needed for safety and sponsor the world’s most comprehensive UBI experiment.\n","\n","Index 23: We have attempted to set up our structure in a way that aligns our incentives with a good outcome.\n","\n","Index 24: We think it’s important that efforts like ours submit to independent audits before releasing new systems; we will talk about this in more detail later this year. At some point, it may be important to get independent review before starting to train future systems, and for the most advanced efforts to agree to limit the rate of growth of compute used for creating new models. We think public standards about when an AGI effort should stop a training run, decide a model is safe to release, or pull a model from production use are important. Finally, we think it’s important that major world governments have insight about training runs above a certain scale.\n","\n","Index 25: We believe that the future of humanity should be determined by humanity, and that it’s important to share information about progress with the public. There should be great scrutiny of all efforts attempting to build AGI and public consultation for major decisions.\n","\n","Index 26: The first AGI will be just a point along the continuum of intelligence. We think it’s likely that progress will continue from there, possibly sustaining the rate of progress we’ve seen over the past decade for a long period of time. If this is true, the world could become extremely different from how it is today, and the risks could be extraordinary. A misaligned superintelligent AGI could cause grievous harm to the world; an autocratic regime with a decisive superintelligence lead could do that too.\n","\n","Index 27: AI that can accelerate science is a special case worth thinking about, and perhaps more impactful than everything else. It’s possible that AGI capable enough to accelerate its own progress could cause major changes to happen surprisingly quickly (and even if the transition starts slowly, we expect it to happen pretty quickly in the final stages). We think a slower takeoff is easier to make safe, and coordination among AGI efforts to slow down at critical junctures will likely be important (even in a world where we don’t need to do this to solve technical alignment problems, slowing down may be important to give society enough time to adapt).\n","\n","Index 28: Successfully transitioning to a world with superintelligence is perhaps the most important—and hopeful, and scary—project in human history. Success is far from guaranteed, and the stakes (boundless downside and boundless upside) will hopefully unite all of us.\n","\n","Index 29: We can imagine a world in which humanity flourishes to a degree that is probably impossible for any of us to fully visualize yet. We hope to contribute to the world an AGI aligned with such flourishing.\n","\n","Index 30: Thanks to Brian Chesky, Paul Christiano, Jack Clark, Holden Karnofsky, Tasha McCauley, Nate Soares, Kevin Scott, Brad Smith, Helen Toner, Allan Dafoe, and the OpenAI team for reviewing drafts of this.\n","\n"]}]},{"cell_type":"markdown","source":["#### クエリエンジンの作成"],"metadata":{"id":"bslpASlK76w1"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import re\n","\n","# URL of the webpage to fetch and index\n","url = \"https://openai.com/blog/planning-for-agi-and-beyond\"\n","\n","# Fetch the HTML content from the webpage\n","response = requests.get(url)\n","html_content = response.content\n","\n","# Parse the HTML content using BeautifulSoup\n","soup = BeautifulSoup(html_content, \"html.parser\")\n","\n","# Index the content you're interested in\n","# For example, let's extract and index all <p> tags' text content\n","paragraphs = soup.find_all(\"p\")\n","indexed_content = [p.get_text() for p in paragraphs]\n","\n","# User query\n","user_query = \"search query terms here\"\n","\n","# Compile regex pattern based on query terms\n","query_pattern = re.compile(rf\".*{'|'.join(user_query.split())}.*\", re.IGNORECASE)\n","\n","# Search for matching content in the indexed content\n","matching_content = [content for content in indexed_content if query_pattern.match(content)]\n","\n","# Print the matching content\n","if matching_content:\n","    print(\"Matching content:\")\n","    for idx, content in enumerate(matching_content, start=1):\n","        print(f\"Result {idx}: {content}\\n\")\n","else:\n","    print(\"No matching content found.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693536640867,"user_tz":-540,"elapsed":5,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"acf5305c-0e24-43a3-d710-8948a1739c6b","id":"PfmA5mI-76w1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): openai.com:443\n","DEBUG:urllib3.connectionpool:https://openai.com:443 \"GET /blog/planning-for-agi-and-beyond HTTP/1.1\" 200 None\n","Matching content:\n","Result 1: Generally speaking, we think more usage of AI in the world will lead to good, and want to promote it (by putting models in our API, open-sourcing them, etc.). We believe that democratized access will also lead to more and better research, decentralized power, more benefits, and a broader set of people contributing new ideas.\n","\n"]}]},{"cell_type":"markdown","source":["#### 質問応答の命令"],"metadata":{"id":"t0u0FWlw76w1"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import re\n","\n","class SimpleQueryEngine:\n","    def __init__(self, url):\n","        self.url = url\n","        self.indexed_content = self.index_content()\n","\n","    def index_content(self):\n","        response = requests.get(self.url)\n","        html_content = response.content\n","        soup = BeautifulSoup(html_content, \"html.parser\")\n","        paragraphs = soup.find_all(\"p\")\n","        indexed_content = [p.get_text() for p in paragraphs]\n","        return indexed_content\n","\n","    def query(self, user_query):\n","        query_pattern = re.compile(rf\".*{'|'.join(user_query.split())}.*\", re.IGNORECASE)\n","        matching_content = [content for content in self.indexed_content if query_pattern.match(content)]\n","        return matching_content\n","\n","# URL of the webpage to fetch and index\n","url = \"https://openai.com/blog/planning-for-agi-and-beyond\"\n","\n","# Create a query engine instance\n","query_engine = SimpleQueryEngine(url)\n","\n","# User query\n","user_query = \"There are several things we think are important to do now to prepare for AGI.\"\n","\n","# Search and print matching content\n","matching_content = query_engine.query(user_query)\n","if matching_content:\n","    print(\"Matching content:\")\n","    for idx, content in enumerate(matching_content, start=1):\n","        print(f\"Result {idx}: {content}\\n\")\n","else:\n","    print(\"No matching content found.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693536807607,"user_tz":-540,"elapsed":1000,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"355d8bfc-bbd9-4e0b-98ef-00000cd01ce7","id":"CEpJ1aE676w1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): openai.com:443\n","DEBUG:urllib3.connectionpool:https://openai.com:443 \"GET /blog/planning-for-agi-and-beyond HTTP/1.1\" 200 None\n","Matching content:\n","Result 1: AGI has the potential to give everyone incredible new capabilities; we can imagine a world where all of us have access to help with almost any cognitive task, providing a great force multiplier for human ingenuity and creativity.\n","\n","Result 2: There are several things we think are important to do now to prepare for AGI.\n","\n","Result 3: We currently believe the best way to successfully navigate AI deployment challenges is with a tight feedback loop of rapid learning and careful iteration. Society will face major questions about what AI systems are allowed to do, how to combat bias, how to deal with job displacement, and more. The optimal decisions will depend on the path the technology takes, and like any new field, most expert predictions have been wrong so far. This makes planning in a vacuum very difficult.[^planning]\n","\n","Result 4: We will need to develop new alignment techniques as our models become more powerful (and tests to understand when our current techniques are failing). Our plan in the shorter term is to use AI to help humans evaluate the outputs of more complex models and monitor complex systems, and in the longer term to use AI to help us come up with new ideas for better alignment techniques.\n","\n","Result 5: Importantly, we think we often have to make progress on AI safety and capabilities together. It’s a false dichotomy to talk about them separately; they are correlated in many ways. Our best safety work has come from working with our most capable models. That said, it’s important that the ratio of safety progress to capability progress increases.\n","\n","Result 6: We have attempted to set up our structure in a way that aligns our incentives with a good outcome.\n","\n","Result 7: We think it’s important that efforts like ours submit to independent audits before releasing new systems; we will talk about this in more detail later this year. At some point, it may be important to get independent review before starting to train future systems, and for the most advanced efforts to agree to limit the rate of growth of compute used for creating new models. We think public standards about when an AGI effort should stop a training run, decide a model is safe to release, or pull a model from production use are important. Finally, we think it’s important that major world governments have insight about training runs above a certain scale.\n","\n","Result 8: We believe that the future of humanity should be determined by humanity, and that it’s important to share information about progress with the public. There should be great scrutiny of all efforts attempting to build AGI and public consultation for major decisions.\n","\n","Result 9: The first AGI will be just a point along the continuum of intelligence. We think it’s likely that progress will continue from there, possibly sustaining the rate of progress we’ve seen over the past decade for a long period of time. If this is true, the world could become extremely different from how it is today, and the risks could be extraordinary. A misaligned superintelligent AGI could cause grievous harm to the world; an autocratic regime with a decisive superintelligence lead could do that too.\n","\n","Result 10: We can imagine a world in which humanity flourishes to a degree that is probably impossible for any of us to fully visualize yet. We hope to contribute to the world an AGI aligned with such flourishing.\n","\n"]}]},{"cell_type":"markdown","source":["### Llama:Youtube動画への質問応答\n","\n","データコネクタ「youtube_transcript」を使って、質問応答を行う\n","\n","「youtube-transcript-api」で動画から字幕を取得する\n","\n","youtube-transcript-api 0.5.0\n","\n","https://pypi.org/project/youtube-transcript-api/"],"metadata":{"id":"Ri9Zsr1y_KXn"}},{"cell_type":"markdown","source":["#### ドキュメントの読み込み\n","\n","ドキュメントはURLを使う\n","\n","What can you do with GPT-4?\n","\n","https://www.youtube.com/watch?v=oc6RV5c1yd0"],"metadata":{"id":"BXFLwk9z2mjQ"}},{"cell_type":"code","source":["from llama_index import download_loader\n","\n","# ドキュメントの読み込み\n","YoutubeTranscriptReader = download_loader(\"YoutubeTranscriptReader\")\n","loader = YoutubeTranscriptReader()\n","documents = loader.load_data(ytlinks=[\"https://www.youtube.com/watch?v=oc6RV5c1yd0\"])"],"metadata":{"id":"484_yFnV-6J-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### インデックスの作成"],"metadata":{"id":"OTiaXfjc2qGe"}},{"cell_type":"code","source":["!pip install llama-index faiss-gpu"],"metadata":{"id":"RfLk0WBdr2Tn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index import LlamaIndex, VectorStoreIndex\n","import numpy as np\n","\n","# Load the pre-trained vectors (you can replace this with your transcript data)\n","documents = [\n","    \"This is the transcript of the first YouTube video.\",\n","    \"The second video transcript is here.\",\n","    # Add more transcript texts...\n","]\n","\n","# Convert transcript texts to embeddings (you'll need to use your own embedding method)\n","embeddings = np.random.rand(len(documents), 768)  # Replace with actual embeddings\n","\n","# Create an index\n","index = LlamaIndex(VectorStoreIndex(embeddings))\n","index.index()"],"metadata":{"id":"LhK1M1V1r5Ro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index import GPTVectorStoreIndex\n","\n","# インデックスの作成\n","index = GPTVectorStoreIndex.from_documents(documents)"],"metadata":{"id":"mON1PpKt-6HV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### クエリエンジンの作成"],"metadata":{"id":"OlcU_8Zn2tKz"}},{"cell_type":"code","source":["# クエリエンジンの作成\n","query_engine = index.as_query_engine()"],"metadata":{"id":"mJsDqemW-6EC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 質問応答の命令"],"metadata":{"id":"ncKOXyN_2v24"}},{"cell_type":"code","source":["# 質問応答\n","print(query_engine.query(\"この動画で伝えたいことはなんですか？日本語で答えて\"))"],"metadata":{"id":"dbaLuJdF-6BL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index import SimpleURLReader, LlamaIndex\n","\n","# Create an index using SimpleURLReader to read web content\n","web_documents = SimpleURLReader(urls=[\"https://en.wikipedia.org/wiki/Artificial_intelligence\"]).load_data()\n","index = LlamaIndex()\n","index.build_index(web_documents)\n","\n","# Define a query engine\n","class WebQueryEngine:\n","    def __init__(self, index):\n","        self.index = index\n","\n","    def query(self, question):\n","        results = self.index.search(question, num_results=1)  # Retrieve 1 result\n","        if results:\n","            return results[0]  # Return the first result\n","        else:\n","            return \"No relevant information found.\"\n","\n","# Create a query engine instance\n","query_engine = WebQueryEngine(index)\n","\n","# Query the index and get a response\n","query = \"What is artificial intelligence?\"\n","response = query_engine.query(query)\n","print(response)"],"metadata":{"id":"Y9b67rY8rUNL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LlamaIndexが実行でない場合:代行例\n","\n","from youtube_transcript_api import YouTubeTranscriptApi\n","\n","from transformers import AutoTokenizer, AutoModel\n","\n","import faiss"],"metadata":{"id":"JgwPIddo9nuk"}},{"cell_type":"markdown","source":["### Faiss:Youtube動画への質問応答\n","\n","データコネクタ「youtube_transcript」を使って、質問応答を行う\n","\n","「youtube-transcript-api」で動画から字幕を取得する\n","\n","youtube-transcript-api 0.5.0\n","\n","https://pypi.org/project/youtube-transcript-api/"],"metadata":{"id":"lIGKE6Bm9oKY"}},{"cell_type":"markdown","source":["#### ドキュメントの読み込み\n","\n","ドキュメントはURLを使う\n","\n","What can you do with GPT-4?\n","\n","https://www.youtube.com/watch?v=oc6RV5c1yd0"],"metadata":{"id":"s5wt_pYi9oKY"}},{"cell_type":"code","source":["!pip install youtube-transcript-api"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693536989365,"user_tz":-540,"elapsed":3911,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"982ed72f-4940-4587-b32b-ac4ba9a19771","id":"WeSUJM_F9oKY"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting youtube-transcript-api\n","  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.7.22)\n","Installing collected packages: youtube-transcript-api\n","Successfully installed youtube-transcript-api-0.6.1\n"]}]},{"cell_type":"code","source":["from youtube_transcript_api import YouTubeTranscriptApi\n","\n","class YoutubeTranscriptReader:\n","    def __init__(self):\n","        pass\n","\n","    def load_data(self, ytlinks):\n","        documents = []\n","        for link in ytlinks:\n","            try:\n","                video_id = self.extract_video_id(link)\n","                transcript = YouTubeTranscriptApi.get_transcript(video_id)\n","                text = \" \".join([entry[\"text\"] for entry in transcript])\n","                documents.append(text)\n","            except Exception as e:\n","                print(f\"Error processing {link}: {str(e)}\")\n","        return documents\n","\n","    def extract_video_id(self, url):\n","        video_id = url.split(\"v=\")[1]\n","        ampersand_position = video_id.find(\"&\")\n","        if ampersand_position != -1:\n","            video_id = video_id[:ampersand_position]\n","        return video_id\n","\n","# YouTube video links to fetch transcripts from\n","ytlinks = [\"https://www.youtube.com/watch?v=oc6RV5c1yd0\"]\n","\n","# Create a transcript reader instance\n","transcript_reader = YoutubeTranscriptReader()\n","\n","# Load and process transcript data\n","documents = transcript_reader.load_data(ytlinks)\n","print(documents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693536993404,"user_tz":-540,"elapsed":512,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"8ac41d84-b3ae-4f5e-fc4d-83dcd8e6aed1","id":"Ty9mKO4-9oKZ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.youtube.com:443\n","DEBUG:urllib3.connectionpool:https://www.youtube.com:443 \"GET /watch?v=oc6RV5c1yd0 HTTP/1.1\" 200 None\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.youtube.com:443\n","DEBUG:urllib3.connectionpool:https://www.youtube.com:443 \"GET /api/timedtext?v=oc6RV5c1yd0&ei=4FLxZN3UBrmnx_AP1Z2a4A0&caps=asr&opi=112496729&xoaf=5&hl=en&ip=0.0.0.0&ipbits=0&expire=1693562192&sparams=ip,ipbits,expire,v,ei,caps,opi,xoaf&signature=06E4A9ABEFF179D237A60EF4CDADC71020680F1E.3BA73830BF1943925A6ECDED57C40319DC0F6134&key=yt8&lang=en HTTP/1.1\" 200 None\n","[\"GPT-4 is the latest AI system from OpenAI. The lab that created Dall-E. And ChatGPT. GPT-4 is a breakthrough in\\nproblem solving capabilities. For example, you can ask it how\\nyou would clean the inside of a tank filled with piranhas. And it'll give you something useful. It can also read, analyze, or\\ngenerate up to 25,000 words of text. It can write code in all\\nmajor programming languages. And it understands images as input, and can reason with them\\nin sophisticated ways. Most importantly, after we created GPT-4,\\nwe spent months making it safer and more aligned with how you want to use it. The methods we've developed to\\ncontinuously improve GPT-4 will help us as we work towards AI\\nsystems that will empower us all.\"]\n"]}]},{"cell_type":"markdown","source":["#### インデックスの作成"],"metadata":{"id":"b0dydtV39oKZ"}},{"cell_type":"code","source":["!pip install faiss-gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693538800031,"user_tz":-540,"elapsed":6692,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"dca85b67-e906-47df-da86-53c2fdc622c5","id":"msmnMX1c9oKZ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"]}]},{"cell_type":"code","source":["!pip install youtube_transcript_api\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693538932193,"user_tz":-540,"elapsed":24185,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"06cddae7-5c38-402f-8257-91545e950ca2","id":"moC5T3FI9oKZ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: youtube_transcript_api in /usr/local/lib/python3.10/dist-packages (0.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.7.22)\n","Collecting transformers\n","  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from youtube_transcript_api import YouTubeTranscriptApi\n","from transformers import AutoTokenizer, AutoModel\n","import faiss\n","\n","class YoutubeTranscriptReader:\n","    def __init__(self):\n","        pass\n","\n","    def load_data(self, ytlinks):\n","        documents = []\n","        for link in ytlinks:\n","            try:\n","                video_id = self.extract_video_id(link)\n","                transcript = YouTubeTranscriptApi.get_transcript(video_id)\n","                text = \" \".join([entry[\"text\"] for entry in transcript])\n","                documents.append(text)\n","            except Exception as e:\n","                print(f\"Error processing {link}: {str(e)}\")\n","        return documents\n","\n","    def extract_video_id(self, url):\n","        video_id = url.split(\"v=\")[1]\n","        ampersand_position = video_id.find(\"&\")\n","        if ampersand_position != -1:\n","            video_id = video_id[:ampersand_position]\n","        return video_id"],"metadata":{"id":"_HQxXTpu9oKa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ytlinks = [\"https://www.youtube.com/watch?v=oc6RV5c1yd0\"]\n","transcript_reader = YoutubeTranscriptReader()\n","documents = transcript_reader.load_data(ytlinks)\n","print(documents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693540102196,"user_tz":-540,"elapsed":367,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"35fa953f-bb60-47ac-b7b2-7a1518531f53","id":"DNXT9BzP9oKa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.youtube.com:443\n","DEBUG:urllib3.connectionpool:https://www.youtube.com:443 \"GET /watch?v=oc6RV5c1yd0 HTTP/1.1\" 200 None\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.youtube.com:443\n","DEBUG:urllib3.connectionpool:https://www.youtube.com:443 \"GET /api/timedtext?v=oc6RV5c1yd0&ei=BV_xZLTOC529x_APyI6GoA8&caps=asr&opi=112496729&xoaf=5&hl=en&ip=0.0.0.0&ipbits=0&expire=1693565301&sparams=ip,ipbits,expire,v,ei,caps,opi,xoaf&signature=68D032D4A0E8889399BD29BF98A2E904F5F1BC10.82ED7EE9966F345B9A59BE890E4E80B464B28F0C&key=yt8&lang=en HTTP/1.1\" 200 None\n","[\"GPT-4 is the latest AI system from OpenAI. The lab that created Dall-E. And ChatGPT. GPT-4 is a breakthrough in\\nproblem solving capabilities. For example, you can ask it how\\nyou would clean the inside of a tank filled with piranhas. And it'll give you something useful. It can also read, analyze, or\\ngenerate up to 25,000 words of text. It can write code in all\\nmajor programming languages. And it understands images as input, and can reason with them\\nin sophisticated ways. Most importantly, after we created GPT-4,\\nwe spent months making it safer and more aligned with how you want to use it. The methods we've developed to\\ncontinuously improve GPT-4 will help us as we work towards AI\\nsystems that will empower us all.\"]\n"]}]},{"cell_type":"code","source":["model_name = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModel.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693540106467,"user_tz":-540,"elapsed":1780,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"d43c13dd-b090-46b8-b18a-2c31a404d154","id":"g7GR-UzW9oKa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n","DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch  # Import the torch library\n","from youtube_transcript_api import YouTubeTranscriptApi\n","from transformers import AutoTokenizer, AutoModel\n","import faiss\n","\n","embeddings = []\n","\n","for document in documents:\n","    inputs = tokenizer(document, return_tensors=\"pt\", padding=True, truncation=True)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n","        embeddings.append(embedding)\n","\n","embeddings_np = np.array(embeddings)\n","normalized_embeddings = faiss.normalize_L2(embeddings_np)"],"metadata":{"id":"5vIlZfaP9oKb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from youtube_transcript_api import YouTubeTranscriptApi\n","from transformers import AutoTokenizer, AutoModel\n","import faiss\n","\n","\n","# Compute document embeddings\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","    embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n","\n","# Normalize embeddings\n","normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n","\n","# Create FAISS index\n","d = normalized_embeddings.shape[1]  # Dimension of embeddings\n","index = faiss.IndexFlatIP(d)  # Index type\n","index.add(normalized_embeddings)"],"metadata":{"id":"9GTAlvQa9oKb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query_embedding = normalized_embeddings[0]  # Use the first embedding as the query\n","k = 5  # Number of nearest neighbors to retrieve\n","distances, indices = index.search(np.expand_dims(query_embedding, 0), k)\n","print(\"Nearest neighbors:\")\n","for i, idx in enumerate(indices[0]):\n","    print(f\"Document {idx}: Similarity {1 - distances[0][i]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693540421441,"user_tz":-540,"elapsed":358,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"79d459ea-5bdb-4ad9-d40c-fdab9127ae68","id":"7hPB7Sgu9oKb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Nearest neighbors:\n","Document 0: Similarity 2.980232238769531e-07\n","Document -1: Similarity 3.4028234663852886e+38\n","Document -1: Similarity 3.4028234663852886e+38\n","Document -1: Similarity 3.4028234663852886e+38\n","Document -1: Similarity 3.4028234663852886e+38\n"]}]},{"cell_type":"markdown","source":["### OR"],"metadata":{"id":"Hsood6wf-abi"}},{"cell_type":"code","source":["import numpy as np\n","from youtube_transcript_api import YouTubeTranscriptApi\n","from transformers import AutoTokenizer, AutoModel\n","import faiss\n","\n","# Assuming you have a list of embeddings called 'embeddings'\n","# Convert embeddings to numpy array\n","embeddings_np = np.array(embeddings)\n","\n","# Normalize embeddings (L2 normalization)\n","faiss.normalize_L2(embeddings_np)\n","\n","# Create an index\n","index = faiss.IndexFlatIP(embeddings_np.shape[1])  # Index for inner product search\n","index.add(embeddings_np)\n","\n","# Define a query embedding\n","query_embedding = np.random.rand(embeddings_np.shape[1]).astype(np.float32)\n","query_embedding /= np.linalg.norm(query_embedding)\n","\n","# Perform a k-nearest neighbors search\n","k = 5  # Number of nearest neighbors to retrieve\n","D, I = index.search(query_embedding.reshape(1, -1), k)\n","\n","# Print the nearest neighbors and their distances\n","for i in range(k):\n","    print(f\"Nearest Neighbor {i + 1}: Index {I[0][i]}, Distance {D[0][i]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693540723928,"user_tz":-540,"elapsed":2,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"5b980b83-1942-4448-a507-f850471bf6ef","id":"B-Eky8Ef9oKb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Nearest Neighbor 1: Index 0, Distance -0.05963487550616264\n","Nearest Neighbor 2: Index -1, Distance -3.4028234663852886e+38\n","Nearest Neighbor 3: Index -1, Distance -3.4028234663852886e+38\n","Nearest Neighbor 4: Index -1, Distance -3.4028234663852886e+38\n","Nearest Neighbor 5: Index -1, Distance -3.4028234663852886e+38\n"]}]},{"cell_type":"markdown","source":["#### クエリエンジンの作成"],"metadata":{"id":"9CZoiMd29oKc"}},{"cell_type":"code","source":["def search_query(query_embedding, index, top_k=5):\n","    D, I = index.search(query_embedding, top_k)\n","    return D, I"],"metadata":{"id":"Iirh3t_o9oKc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 質問応答の命令"],"metadata":{"id":"2CUA1jPg9oKc"}},{"cell_type":"code","source":["# Perform a k-nearest neighbors search\n","k = 5  # Number of nearest neighbors to retrieve\n","D, I = index.search(query_embedding.reshape(1, -1), k)\n","\n","# Print the nearest neighbors and their distances\n","for i in range(k):\n","    print(f\"Nearest Neighbor {i + 1}: Index {I[0][i]}, Distance {D[0][i]}\")\n","\n","# Retrieve relevant documents using the indices I\n","relevant_documents = [documents[i] for i in I[0]]\n","\n","# Print the relevant documents\n","for i, doc in enumerate(relevant_documents):\n","    print(f\"Relevant Document {i + 1}: {doc}\")\n","\n","# Query the model for an answer\n","query = \"what does this video like to say?\"\n","response = query_engine.query(query)\n","print(\"Response:\", response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693540978682,"user_tz":-540,"elapsed":741,"user":{"displayName":"宮島由利子","userId":"14382487523079710847"}},"outputId":"888804e8-03b7-4448-f798-51b3aafe30ad","id":"nSGD5sbD9oKc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Nearest Neighbor 1: Index 0, Distance -0.05963487923145294\n","Nearest Neighbor 2: Index -1, Distance -3.4028234663852886e+38\n","Nearest Neighbor 3: Index -1, Distance -3.4028234663852886e+38\n","Nearest Neighbor 4: Index -1, Distance -3.4028234663852886e+38\n","Nearest Neighbor 5: Index -1, Distance -3.4028234663852886e+38\n","Relevant Document 1: GPT-4 is the latest AI system from OpenAI. The lab that created Dall-E. And ChatGPT. GPT-4 is a breakthrough in\n","problem solving capabilities. For example, you can ask it how\n","you would clean the inside of a tank filled with piranhas. And it'll give you something useful. It can also read, analyze, or\n","generate up to 25,000 words of text. It can write code in all\n","major programming languages. And it understands images as input, and can reason with them\n","in sophisticated ways. Most importantly, after we created GPT-4,\n","we spent months making it safer and more aligned with how you want to use it. The methods we've developed to\n","continuously improve GPT-4 will help us as we work towards AI\n","systems that will empower us all.\n","Relevant Document 2: GPT-4 is the latest AI system from OpenAI. The lab that created Dall-E. And ChatGPT. GPT-4 is a breakthrough in\n","problem solving capabilities. For example, you can ask it how\n","you would clean the inside of a tank filled with piranhas. And it'll give you something useful. It can also read, analyze, or\n","generate up to 25,000 words of text. It can write code in all\n","major programming languages. And it understands images as input, and can reason with them\n","in sophisticated ways. Most importantly, after we created GPT-4,\n","we spent months making it safer and more aligned with how you want to use it. The methods we've developed to\n","continuously improve GPT-4 will help us as we work towards AI\n","systems that will empower us all.\n","Relevant Document 3: GPT-4 is the latest AI system from OpenAI. The lab that created Dall-E. And ChatGPT. GPT-4 is a breakthrough in\n","problem solving capabilities. For example, you can ask it how\n","you would clean the inside of a tank filled with piranhas. And it'll give you something useful. It can also read, analyze, or\n","generate up to 25,000 words of text. It can write code in all\n","major programming languages. And it understands images as input, and can reason with them\n","in sophisticated ways. Most importantly, after we created GPT-4,\n","we spent months making it safer and more aligned with how you want to use it. The methods we've developed to\n","continuously improve GPT-4 will help us as we work towards AI\n","systems that will empower us all.\n","Relevant Document 4: GPT-4 is the latest AI system from OpenAI. The lab that created Dall-E. And ChatGPT. GPT-4 is a breakthrough in\n","problem solving capabilities. For example, you can ask it how\n","you would clean the inside of a tank filled with piranhas. And it'll give you something useful. It can also read, analyze, or\n","generate up to 25,000 words of text. It can write code in all\n","major programming languages. And it understands images as input, and can reason with them\n","in sophisticated ways. Most importantly, after we created GPT-4,\n","we spent months making it safer and more aligned with how you want to use it. The methods we've developed to\n","continuously improve GPT-4 will help us as we work towards AI\n","systems that will empower us all.\n","Relevant Document 5: GPT-4 is the latest AI system from OpenAI. The lab that created Dall-E. And ChatGPT. GPT-4 is a breakthrough in\n","problem solving capabilities. For example, you can ask it how\n","you would clean the inside of a tank filled with piranhas. And it'll give you something useful. It can also read, analyze, or\n","generate up to 25,000 words of text. It can write code in all\n","major programming languages. And it understands images as input, and can reason with them\n","in sophisticated ways. Most importantly, after we created GPT-4,\n","we spent months making it safer and more aligned with how you want to use it. The methods we've developed to\n","continuously improve GPT-4 will help us as we work towards AI\n","systems that will empower us all.\n","Response: ['Although we cannot predict exactly what will happen, and of course our current progress could hit a wall, we can articulate the principles we care about\\xa0most:', 'A gradual transition gives people, policymakers, and institutions time to understand what’s happening, personally experience the benefits and downsides of these systems, adapt our economy, and to put regulation in place. It also allows for society and AI to co-evolve, and for people collectively to figure out what they want while the stakes are relatively\\xa0low.', 'We currently believe the best way to successfully navigate AI deployment challenges is with a tight feedback loop of rapid learning and careful iteration. Society will face major questions about what AI systems are allowed to do, how to combat bias, how to deal with job displacement, and more. The optimal decisions will depend on the path the technology takes, and like any new field, most expert predictions have been wrong so far. This makes planning in a vacuum very difficult.[^planning]', 'In particular, we think it’s important that society agree on extremely wide bounds of how AI can be used, but that within those bounds, individual users have a lot of discretion. Our eventual hope is that the institutions of the world agree on what these wide bounds should be; in the shorter term we plan to run experiments for external input. The institutions of the world will need to be strengthened with additional capabilities and experience to be prepared for complex decisions about\\xa0AGI.']\n"]}]},{"cell_type":"markdown","source":["## ベクトルデータベース"],"metadata":{"id":"C8Vi9mCU_Thg"}},{"cell_type":"markdown","source":["ベクトルデータベース\n","\n","*Faissデータベース\n","\n","https://github.com/facebookresearch/faiss\n","\n","*Pineconeデータベース（有料/無料試しあり）\n","\n","https://www.pinecone.io/\n","\n","*Qdrantデータベース\n","\n","https://qdrant.tech/\n","\n","*Chromaデータベース\n","\n","https://docs.trychroma.com/\n","\n","*Milvusデータベース\n","\n","https://milvus.io/\n","\n","*Waviateデータベース\n","\n","https://weaviate.io/"],"metadata":{"id":"9V2B3YGS-dIN"}},{"cell_type":"markdown","source":["### Faiss を使った質問応答の実践例"],"metadata":{"id":"-Kr_Nf2G-fc-"}},{"cell_type":"code","source":["!pip install -q llama-index\n","!pip install -q openai\n","!pip install -q transformers\n","!pip install -q accelerate"],"metadata":{"id":"VO1vY0OZ-hsJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.llms import OpenAI\n","from llama_index import VectorStoreIndex, SimpleDirectoryReader\n","from IPython.display import Markdown, display\n","from llama_index import GPTVectorStoreIndex, StorageContext\n","from llama_index.vector_stores.faiss import FaissVectorStore"],"metadata":{"id":"Uf-aenL7-kSm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\""],"metadata":{"id":"1fIZaiWN-kO2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q faiss-gpu"],"metadata":{"id":"t6zuypCN-kKi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin1.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin2.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin3.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin4.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin5.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin6.txt\n","!wget https://raw.githubusercontent.com/Miyjy/general_resources/main/data/akazukin7.txt"],"metadata":{"id":"NCX5kJzj-kGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pypdf"],"metadata":{"id":"1j46smng-kCC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import faiss\n","\n","faiss_index = faiss.IndexFlatL2(1536)"],"metadata":{"id":"NUaklb5Q-j93"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["documents = SimpleDirectoryReader(\"data\").load_data()"],"metadata":{"id":"MooDj7Dz-j4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index = VectorStoreIndex.from_documents(documents)"],"metadata":{"id":"0R6pAvdh-j0v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index import GPTVectorStoreIndex, StorageContext\n","from llama_index.vector_stores.faiss import FaissVectorStore\n","\n","# インデックスの作成\n","vector_store = FaissVectorStore(faiss_index=faiss_index)\n","storage_context = StorageContext.from_defaults(vector_store=vector_store)\n","index = GPTVectorStoreIndex.from_documents(\n","    documents,\n","    storage_context=storage_context\n",")"],"metadata":{"id":"tRAa_aXx-ju1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# クエリエンジンの作成\n","query_engine = index.as_query_engine()"],"metadata":{"id":"YIF7any2-jl-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 質問応答\n","print(query_engine.query(\"ミコの幼馴染の名前は？\"))"],"metadata":{"id":"akOBPnaK-jX4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pinecone\n","\n","Pineconeの特徴\n","\n","|項目|特徴|\n","|-|-|\n","|高速|数10億のデータがあり、クリエは高速|\n","フレッシュ|データの追加・編集・削除時に、インデックスを動的更新|\n","|フィルタリング|ベクトル検索とメタデータフィルタを組み合わせて、より関連性の高いデータをすばやく取得|\n","|フルマネージド|開始、仕様、スケーリングが簡単でスムーズで安全|\n","\n","\n","利用料金:\n","\n","７日間試し無料期間\n","\n","詳細料金:\n","\n","https://www.pinecone.io/pricing/\n","\n","Pinecone利用登録およびAPIキー取得\n","\n","<figure>\n","<a href=\"https://www.pinecone.io/pricing/\n","\"><img src='https://raw.githubusercontent.com/Miyjy/OpenAI_GPT4_ChatGPT_LangChain/main/5/figures/fig5.12.png' alt='登録画面' width='640' border='1'></a>\n","</figure>\n","\n","図5.12. 出所:Pinecone公式Webサイト |登録画面"],"metadata":{"id":"LHgD5SQC-1Zd"}},{"cell_type":"markdown","source":["## Pinecone を使った質問応答の実践例"],"metadata":{"id":"NGGt-tCb-5Yd"}},{"cell_type":"code","source":["# パッケージのインストール\n","!pip install pinecone-client\n","!pip install transformers"],"metadata":{"id":"gDBxSORX-4_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index import SimpleDirectoryReader\n","\n","# ドキュメントの読み込み (dataフォルダにドキュメントを配置しておきます)\n","documents = SimpleDirectoryReader(\"data\").load_data()"],"metadata":{"id":"0LZ9_A59KTYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pinecone\n","\n","# pinecone-clientのインデックスの生成\n","api_key = \"<PineconeのAPIキー>\"\n","pinecone.init(api_key=api_key, environment=\"us-west1-gcp\")\n","pinecone.create_index(\n","    \"quickstart\",\n","    dimension=1536,\n","    metric=\"dotproduct\",\n","    pod_type=\"p1\"\n",")\n","pinecone_index = pinecone.Index(\"quickstart\")"],"metadata":{"id":"7VB_QXpKKTVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index import GPTVectorStoreIndex, StorageContext\n","from llama_index.vector_stores.pinecone import PineconeVectorStore\n","\n","# インデックスの作成\n","vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n","storage_context = StorageContext.from_defaults(vector_store=vector_store)\n","index = GPTVectorStoreIndex.from_documents(\n","    documents,\n","    storage_context=storage_context\n",")"],"metadata":{"id":"YvaoD--sKTSV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# クエリエンジンの作成\n","query_engine = index.as_query_engine()"],"metadata":{"id":"mNNYCkDIKTPx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 質問応答\n","print(query_engine.query(\"ミコの幼馴染の名前は？\"))"],"metadata":{"id":"NSKUd4BsKTND"},"execution_count":null,"outputs":[]}]}